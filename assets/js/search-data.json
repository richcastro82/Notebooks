{
  
    
        "post0": {
            "title": "PEPSI MATRIX",
            "content": "#IMPORT LIBRARIES AND DATASETS import pandas as pd pepsiLocations=pd.read_csv(&#39;../_data/pepsi_locations.csv&#39;) rt=pd.read_csv(&#39;../_data/rt.csv&#39;) cen=pd.read_csv(&#39;../_data/cen.csv&#39;) rt.columns=map(str.lower, rt.columns) rt=rt.rename(columns={&#39;region&#39;:&#39;state&#39;}) rtCol=[&#39;date&#39;, &#39;state&#39;, &#39;mean&#39;] rta=rt[rtCol] cen.columns=map(str.lower, cen.columns) cenCol=[&#39;fips&#39;, &#39;stname&#39;,&#39;popestimate2019&#39;] cena=cen[cenCol] cena=cena.rename(columns={&#39;stname&#39;:&#39;state&#39;, &#39;ctyname&#39;:&#39;city&#39;, &#39;popestimate2019&#39;:&#39;pop&#39;}) rta=rta.rename(columns={&#39;state&#39;:&#39;st&#39;}) . pepsiLocations.head() . uid fips country facility state st address city county . 0 8405031 | 5031 | USA | Jonesboro, AR | Arkansas | AR | 2810 Quality Way | Jonesboro | Craighead | . 1 8404021 | 4021 | USA | Casa Grande, AZ (Frito Lay) | Azizona | AZ | 1450 W Maricopa Hwy | Casa Grande | Pinal | . 2 8406029 | 6029 | USA | Bakersfield, CA (Frito Lay) | California | CA | 28801 Highway 58 | Bakersfield | Kern | . 3 8406099 | 6099 | USA | Modesto, CA | California | CA | 600 Gardner Road | Modesto | Stanislaus | . 4 8406071 | 6071 | USA | Rancho Cucamonga, CA | California | CA | 9535 Archibald Ave | Rancho Cucamonga | San Bernardino | . pep=pd.merge(pepsiLocations.astype(str), cena, on=[&#39;fips&#39;]) . cena . fips state pop . 0 1001 | Alabama | 55869 | . 1 1003 | Alabama | 223234 | . 2 1005 | Alabama | 24686 | . 3 1007 | Alabama | 22394 | . 4 1009 | Alabama | 57826 | . ... ... | ... | ... | . 3137 56037 | Wyoming | 42343 | . 3138 56039 | Wyoming | 23464 | . 3139 56041 | Wyoming | 20226 | . 3140 56043 | Wyoming | 7805 | . 3141 56045 | Wyoming | 6927 | . 3142 rows × 3 columns . pep.shape . (7, 10) . pep.columns . Index([&#39;uid&#39;, &#39;fips&#39;, &#39;country&#39;, &#39;facility&#39;, &#39;state&#39;, &#39;st&#39;, &#39;address&#39;, &#39;city&#39;, &#39;county&#39;, &#39;pop&#39;], dtype=&#39;object&#39;) . pep . uid fips country facility state_x st address city county state_y pop . 0 8405031 | 5031 | USA | Jonesboro, AR | Arkansas | AR | 2810 Quality Way | Jonesboro | Craighead | Arkansas | 23457 | . 1 8404021 | 4021 | USA | Casa Grande, AZ (Frito Lay) | Azizona | AZ | 1450 W Maricopa Hwy | Casa Grande | Pinal | Arizona | 110924 | . 2 8406029 | 6029 | USA | Bakersfield, CA (Frito Lay) | California | CA | 28801 Highway 58 | Bakersfield | Kern | California | 181215 | . 3 8406099 | 6099 | USA | Modesto, CA | California | CA | 600 Gardner Road | Modesto | Stanislaus | California | 447643 | . 4 8406071 | 6071 | USA | Rancho Cucamonga, CA | California | CA | 9535 Archibald Ave | Rancho Cucamonga | San Bernardino | California | 1552058 | . 5 8408031 | 8031 | USA | Denver, CO (Frito Lay) | Colorado | CO | 11645 East 37th Avenue | Denver | Denver | Colorado | 6061 | . 6 8409015 | 9015 | USA | Dayville, CT | nan | CT | 1886 Upper Maple St | Dayville | Windham | Connecticut | 854757 | . 7 84012095 | 12095 | USA | Orlando, FL (Frito Lay) | Florida | FL | 2800 Silver Star Road | Orlando | Orange | Florida | 88625 | . 8 84013153 | 13153 | USA | Kathleen, GA | Georgia | GA | 1200 Georgia Hwy 247 S | Kathleen | Houston | Georgia | 26205 | . 9 84013153 | 13153 | USA | Cedar Rapids, IA (Pepsi Quaker Foods) | nan | IA | 418 2nd St NE | Cedar Rapids | Linn | Georgia | 26205 | . 10 84013153 | 13153 | USA | Bridgeview, IL | Illinois | IL | 7700 W 71st Street | Bridgeview | Cook | Georgia | 26205 | . 11 84013153 | 13153 | USA | Danville, IL | Illinois | IL | 1703 E Voorhees Street | Danville | Vermilion | Georgia | 26205 | . 12 84013153 | 13153 | USA | Frankfort, IN (FL S County Rd) | nan | IN | 323 S County Road 300 West | Frankfort | Clinton | Georgia | 26205 | . 13 84013153 | 13153 | USA | Frankfort, IN (FL W County Rd) | nan | IN | 2611 W County Road O NS | Frankfort | Clinton | Georgia | 26205 | . 14 84013153 | 13153 | USA | Topeka, KS | Kansas | KS | 4236 Kirklawn Avenue | Topeka | Shawnee | Georgia | 26205 | . 15 84013153 | 13153 | USA | Randolph, MA | nan | MA | 663 North St | Randolph | Norfolk | Georgia | 26205 | . 16 84013153 | 13153 | USA | Aberdeen, MD | nan | MD | 800 Hickory Road | Aberdeen | Harford | Georgia | 26205 | . 17 84013153 | 13153 | USA | Columbia, MO | nan | MO | 4501 Paris Rd | Columbia | Boone | Georgia | 26205 | . 18 84013153 | 13153 | USA | Charlotte, NC (Frito Lay) | nan | NC | 2911 Nevada Boulevard | Charlotte | Mecklenburg | Georgia | 26205 | . 19 84013153 | 13153 | USA | Binghampton, NY | nan | NY | Broome Industrial Park 10 Spud Ln | Binghampton | Broome | Georgia | 26205 | . 20 84013153 | 13153 | USA | Canton, OH | Ohio | OH | 4030 16th Street SW | Canton | Stark | Georgia | 26205 | . 21 84013153 | 13153 | USA | Wooster, OH | Ohio | OH | 1626 Old Mansfield Road | Wooster | Wayne | Georgia | 26205 | . 22 84013153 | 13153 | USA | Williamsport, PA (Frito Lay) | Pennsylvania | PA | 220 North Reach Road | Williamsport | Lycoming | Georgia | 26205 | . 23 84013153 | 13153 | USA | York, PA | Pennsylvania | PA | 3553 Gillespie Dr | York | York | Georgia | 26205 | . 24 84013153 | 13153 | USA | Fayetteville, TN | Tennessee | TN | 101 Industrial Blvd | Fayetteville | Lincoln | Georgia | 26205 | . 25 84013153 | 13153 | USA | Pulaski, TN | Tennessee | TN | 298 Industrial Blvd | Pulaski | Giles | Georgia | 26205 | . 26 84013153 | 13153 | USA | Arlington, TX (Frito-Lay) | Texas | TX | 948 Avenue H East | Arlington | Tarrant | Georgia | 26205 | . 27 84013153 | 13153 | USA | Irving, TX | Texas | TX | 701 N Wildwood | Irving | Dallas | Georgia | 26205 | . 28 84013153 | 13153 | USA | Rosenberg , TX | Texas | TX | 3310 Hwy 36 North | Rosenberg | Fort Bend | Georgia | 26205 | . 29 84013153 | 13153 | USA | San Antonio, TX (Frito Lay) | Texas | TX | 4855 Greatland Drive | San Antonio | Bexar | Georgia | 26205 | . 30 84013153 | 13153 | USA | Salt Lake City, UT (Frito Lay) | nan | UT | 6301 West 4700 South | Salt Lake City | Salt Lake | Georgia | 26205 | . 31 84013153 | 13153 | USA | Lynchburg, VA | nan | VA | 230 Jefferson Ridge Parkway | Lynchburg | Campbell | Georgia | 26205 | . 32 84013153 | 13153 | USA | Vancouver ,WA | nan | WA | 4808 NW Fruit Valley Rd | Vancouver | Clark | Georgia | 26205 | . 33 84013153 | 13153 | USA | Beloit, WI | nan | WI | 2810 Kennedy Drive | Beloit | Rock | Georgia | 26205 | .",
            "url": "https://richcastro82.github.io/Notebooks/matrix/2020/08/30/Pepsi-Matrix.html",
            "relUrl": "/matrix/2020/08/30/Pepsi-Matrix.html",
            "date": " • Aug 30, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "TAG MATRIX DATA SCRAPER",
            "content": "import pandas as pd import requests import datetime date=datetime.datetime.now().strftime(&quot;%Y-%m-%d&quot;) . CANADA STUFF . canadaFull=pd.read_csv(&#39;https://raw.githubusercontent.com/eebrown/data2019nCoV/master/data-raw/covid19.csv&#39;) canadaFull.to_csv(&#39;../_data/data_sources/canadaFull.csv&#39;) canadaCensus=pd.read_csv(&#39;https://www12.statcan.gc.ca/census-recensement/2016/dp-pd/hlt-fst/pd-pl/Tables/CompFile.cfm?Lang=Eng&amp;T=301&amp;OFT=FULLCSV&#39;) . canadaDry=pd.read_csv(&#39;https://raw.githubusercontent.com/ishaberry/Covid19Canada/master/timeseries_prov/cases_timeseries_prov.csv&#39;) canadaDry.to_csv(&#39;../_data/data_sources/canadaCase.csv&#39;) . rtlive=pd.read_csv(&#39;https://d14wlfuexuxgcm.cloudfront.net/covid/rt.csv&#39;) rtlive.to_csv(&#39;../_data/data_sources/rtlive/rtlive&#39;+date+&#39;.csv&#39;) . Mobility Reports . Google Mobility Reports | Apple Mobility Reports | . #GOOGLE AND APPLE MOBILITY DATA BY COUNTY #apple=pd.read_csv(&#39;https://covid19-static.cdn-apple.com/covid19-mobility-data/2014HotfixDev8/v3/en-us/applemobilitytrends-2020-08-08.csv&#39;) #apple.to_csv(&#39;../_data/Data_Sources/Mobility_Reports/apple.csv&#39;) google=pd.read_csv(&#39;https://www.gstatic.com/covid19/mobility/Global_Mobility_Report.csv&#39;) google.to_csv(&#39;../_data/Data_Sources/google/google.csv&#39;) . WORLD-O-METER DATASETS . NEW YORK CALIFORNIA NEW JERSEY PA SOUTH CAROLINA OHIO WASHINGTON STATE &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; healthDepartment=requests.get(&#39;https://data.ct.gov/Health-and-Human-Services/COVID-19-Tests-Cases-and-Deaths-By-Town-/28fr-iqnx/data&#39;) hd=pd.read_html(healthDepartment.text) hd . ValueError Traceback (most recent call last) &lt;ipython-input-18-9beffda8bcc3&gt; in &lt;module&gt; 1 healthDepartment=requests.get(&#39;https://data.ct.gov/Health-and-Human-Services/COVID-19-Tests-Cases-and-Deaths-By-Town-/28fr-iqnx/data&#39;) -&gt; 2 hd=pd.read_html(healthDepartment.text) 3 hd 4 5 C: Users anaconda3 envs USAcovidMAP lib site-packages pandas io html.py in read_html(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only) 1083 ) 1084 validate_header_arg(header) -&gt; 1085 return _parse( 1086 flavor=flavor, 1087 io=io, C: Users anaconda3 envs USAcovidMAP lib site-packages pandas io html.py in _parse(flavor, io, match, attrs, encoding, displayed_only, **kwargs) 913 break 914 else: --&gt; 915 raise retained 916 917 ret = [] C: Users anaconda3 envs USAcovidMAP lib site-packages pandas io html.py in _parse(flavor, io, match, attrs, encoding, displayed_only, **kwargs) 893 894 try: --&gt; 895 tables = p.parse_tables() 896 except ValueError as caught: 897 # if `io` is an io-like object, check if it&#39;s seekable C: Users anaconda3 envs USAcovidMAP lib site-packages pandas io html.py in parse_tables(self) 211 list of parsed (header, body, footer) tuples from tables. 212 &#34;&#34;&#34; --&gt; 213 tables = self._parse_tables(self._build_doc(), self.match, self.attrs) 214 return (self._parse_thead_tbody_tfoot(table) for table in tables) 215 C: Users anaconda3 envs USAcovidMAP lib site-packages pandas io html.py in _parse_tables(self, doc, match, attrs) 543 544 if not tables: --&gt; 545 raise ValueError(&#34;No tables found&#34;) 546 547 result = [] ValueError: No tables found . #WORLD O METER DATA #NEW YORK COUNTY DATA import datetime date=datetime.datetime.now().strftime(&quot;%Y-%m-%d&quot;) web=requests.get(&#39;https://www.worldometers.info/coronavirus/usa/new-york&#39;) ny=pd.read_html(web.text) ny=ny[1] ny.columns=map(str.lower, ny.columns) ny.to_csv(&#39;../_data/Data_Sources/worldometer/&#39;+date+&#39;NY-County-Data.csv&#39;) #CALIFORNIA COUNTY DATA cad=requests.get(&#39;https://www.worldometers.info/coronavirus/usa/california&#39;) ca=pd.read_html(cad.text) ca=ca[1] ca.columns=map(str.lower, ca.columns) ca.to_csv(&#39;../_data/Data_Sources/worldometer/&#39;+date+&#39;CA-County-Data.csv&#39;) #NEW JERSEY COUNTY DATA njd=requests.get(&#39;https://www.worldometers.info/coronavirus/usa/new-jersey&#39;) nj=pd.read_html(njd.text) nj=nj[1] nj.columns=map(str.lower, nj.columns) nj.to_csv(&#39;../_data/Data_Sources/worldometer/&#39;+date+&#39;NJ-County-Data.csv&#39;) #OHIO COUNTY DATA ohd=requests.get(&#39;https://www.worldometers.info/coronavirus/usa/ohio/&#39;) oh=pd.read_html(ohd.text) oh=oh[1] oh.columns=map(str.lower, oh.columns) oh.to_csv(&#39;../_data/Data_Sources/worldometer/&#39;+date+&#39;OH-County-Data.csv&#39;) #SOUTH CAROLINA COUNTY DATA scd=requests.get(&#39;https://www.worldometers.info/coronavirus/usa/south-carolina/&#39;) sc=pd.read_html(scd.text) sc=sc[1] sc.columns=map(str.lower, sc.columns) sc.to_csv(&#39;../_data/Data_Sources/worldometer/&#39;+date+&#39;SC-County-Data.csv&#39;) #PA COUNTY DATA pad=requests.get(&#39;https://www.worldometers.info/coronavirus/usa/pennsylvania/&#39;) pa=pd.read_html(pad.text) pa=pa[1] pa.columns=map(str.lower, pa.columns) pa.to_csv(&#39;../_data/Data_Sources/worldometer/&#39;+date+&#39;PA-County-Data.csv&#39;) #WASHINGTON COUNTY DATA wad=requests.get(&#39;https://www.worldometers.info/coronavirus/usa/washington/&#39;) wa=pd.read_html(wad.text) wa=wa[1] wa.columns=map(str.lower, wa.columns) wa.to_csv(&#39;../_data/Data_Sources/worldometer/&#39;+date+&#39;WA-County-Data.csv&#39;) #US STATE LEVEL DATA we=requests.get(&#39;https://www.worldometers.info/coronavirus/country/us/&#39;) us=pd.read_html(we.text) us=us[1] us.to_csv(&#39;../_data/Data_Sources/worldometer/&#39;+date+&#39;US-State-Data.csv&#39;) . COUNTY HEALTH DEPARTMANT DATASETS . #HEALTH DEPARTMENTS DATA flData=pd.read_csv(&#39;https://opendata.arcgis.com/datasets/222c9d85e93540dba523939cfb718d76_0.csv?outSR=%7B%22latestWkid%22%3A4326%2C%22wkid%22%3A4326%7D&#39;) flData.to_csv(&#39;../_data/Data_Sources/Fl-Data.csv&#39;) miData=pd.read_excel(&#39;https://www.michigan.gov/documents/coronavirus/Covid-19_Tests_by_County_2020-08-08_698830_7.xlsx&#39;) miData.to_csv(&#39;../_data/Data_Sources/Health-Department-Data/MI-Tests-County.csv&#39;) miData2=pd.read_excel(&#39;https://www.michigan.gov/documents/coronavirus/Cases_by_County_and_Date_2020-08-08_698828_7.xlsx&#39;) miData2.to_csv(&#39;../_data/Data_Sources/Health-Department-Data/MI-Cases-County.csv&#39;) miData3=pd.read_excel(&#39;https://www.michigan.gov/documents/coronavirus/Cases_and_Deaths_by_County_2020-08-08_698827_7.xlsx&#39;) miData3.to_csv(&#39;../_data/Data_Sources/Health-Department-Data/MI-Deaths-Cases-County.csv&#39;) miData4=pd.read_csv(&#39;https://raw.githubusercontent.com/jeffcore/covid-19-usa-by-state/master/COVID-19-Cases-USA-By-County.csv&#39;) miData4.to_csv(&#39;../_data/Data_Sources/Health-Department-Data/COVID-19-Cases-USA-By-County.csv&#39;) miData5=pd.read_csv(&#39;https://raw.githubusercontent.com/jeffcore/covid-19-usa-by-state/master/COVID-19-Deaths-USA-By-County.csv&#39;) miData5.to_csv(&#39;../_data/Data_Sources/Health-Department-Data/COVID-19-Deaths-USA-By-County.csv&#39;) miData6=pd.read_csv(&#39;https://raw.githubusercontent.com/jeffcore/covid-19-usa-by-state/master/COVID-19-Cases-USA-By-State.csv&#39;) miData6.to_csv(&#39;../_data/Data_Sources/Health-Department-Data/COVID-19-Cases-USA-By-State.csv&#39;) miData7=pd.read_csv(&#39;https://raw.githubusercontent.com/jeffcore/covid-19-usa-by-state/master/COVID-19-Deaths-USA-By-State.csv&#39;) miData7.to_csv(&#39;../_data/Data_Sources/Health-Department-Data/COVID-19-Deaths-USA-By-State.csv&#39;) . #ANOTHER MODULE from bs4 import BeautifulSoup url=requests.get(&#39;https://covidactnow.org/us/fl/county/taylor_county?s=846164&#39;) soup = BeautifulSoup(requests.get(url).text) soup.findAll(&quot;table&quot;)[0].findAll(&quot;tr&quot;)[0] . COVID TRACKER DATA . #COVID TRACKER DATA da1=pd.read_html(&#39;https://covidtracking.com/data/state/alabama&#39;) da1[1].to_csv(&#39;../_data/Data_Sources/CovidTracker/Alabama.csv&#39;) da2=pd.read_html(&#39;https://covidtracking.com/data/state/alaska&#39;) da2[1].to_csv(&#39;../_data/Data_Sources/CovidTracker/Alaska.csv&#39;) da3=pd.read_html(&#39;https://covidtracking.com/data/state/arizona&#39;) da3[1].to_csv(&#39;../_data/Data_Sources/CovidTracker/Arizona.csv&#39;) AR_COVIDTRACKER=pd.read_html(&#39;https://covidtracking.com/data/state/arkansas&#39;) AR_COVIDTRACKER[1].to_csv(&#39;../_data/data_sources/covidtracker/&#39;+date+&#39;-ARKANSAS.csv&#39;) CA_COVIDTRACKER=pd.read_html(&#39;https://covidtracking.com/data/state/california&#39;) CA_COVIDTRACKER[1].to_csv(&#39;../_data/data_sources/covidtracker/&#39;+date+&#39;-CALIFORNIA.csv&#39;) GA_COVIDTRACKER=pd.read_html(&#39;https://covidtracking.com/data/state/GEORGIA&#39;) GA_COVIDTRACKER[1].to_csv(&#39;../_data/data_sources/covidtracker/&#39;+date+&#39;-GEORGIA.csv&#39;) KS_COVIDTRACKER=pd.read_html(&#39;https://covidtracking.com/data/state/KANSAS&#39;) KS_COVIDTRACKER[1].to_csv(&#39;../_data/data_sources/covidtracker/&#39;+date+&#39;-KANSAS.csv&#39;) FL_COVIDTRACKER=pd.read_html(&#39;https://covidtracking.com/data/state/FLORIDA&#39;) FL_COVIDTRACKER[1].to_csv(&#39;../_data/data_sources/covidtracker/&#39;+date+&#39;-FLORIDA.csv&#39;) IL_COVIDTRACKER=pd.read_html(&#39;https://covidtracking.com/data/state/ILLINOIS&#39;) IL_COVIDTRACKER[1].to_csv(&#39;../_data/data_sources/covidtracker/&#39;+date+&#39;-ILLINOIS.csv&#39;) OH_COVIDTRACKER=pd.read_html(&#39;https://covidtracking.com/data/state/OHIO&#39;) OH_COVIDTRACKER[1].to_csv(&#39;../_data/data_sources/covidtracker/&#39;+date+&#39;-OHIO.csv&#39;) TN_COVIDTRACKER=pd.read_html(&#39;https://covidtracking.com/data/state/TENNESSEE&#39;) TN_COVIDTRACKER[1].to_csv(&#39;../_data/data_sources/covidtracker/&#39;+date+&#39;-TENNESSEE.csv&#39;) NE_COVIDTRACKER=pd.read_html(&#39;https://covidtracking.com/data/state/NEBRASKA&#39;) NE_COVIDTRACKER[1].to_csv(&#39;../_data/data_sources/covidtracker/&#39;+date+&#39;-NEBRASKA.csv&#39;) PA_COVIDTRACKER=pd.read_html(&#39;https://covidtracking.com/data/state/PENNSYLVANIA&#39;) PA_COVIDTRACKER[1].to_csv(&#39;../_data/data_sources/covidtracker/&#39;+date+&#39;-PENNSYLVANIA.csv&#39;) NC_COVIDTRACKER=pd.read_html(&#39;https://covidtracking.com/data/state/NORTH-CAROLINA&#39;) NC_COVIDTRACKER[1].to_csv(&#39;../_data/data_sources/covidtracker/&#39;+date+&#39;-NORTHCAROLINA.csv&#39;) KY_COVIDTRACKER=pd.read_html(&#39;https://covidtracking.com/data/state/KENTUCKY&#39;) KY_COVIDTRACKER[1].to_csv(&#39;../_data/data_sources/covidtracker/&#39;+date+&#39;-KENTUCKY.csv&#39;) CO_COVIDTRACKER=pd.read_html(&#39;https://covidtracking.com/data/state/COLORADO&#39;) CO_COVIDTRACKER[1].to_csv(&#39;../_data/data_sources/covidtracker/&#39;+date+&#39;-COLORADO.csv&#39;) KS_COVIDTRACKER=pd.read_html(&#39;https://covidtracking.com/data/state/KENTUCKY&#39;) KS_COVIDTRACKER[1].to_csv(&#39;../_data/data_sources/covidtracker/&#39;+date+&#39;-KENTUCKY.csv&#39;) NJ_COVIDTRACKER=pd.read_html(&#39;https://covidtracking.com/data/state/NEW-JERSEY&#39;) NJ_COVIDTRACKER[1].to_csv(&#39;../_data/data_sources/covidtracker/&#39;+date+&#39;-NEWJERSEY.csv&#39;) MN_COVIDTRACKER=pd.read_html(&#39;https://covidtracking.com/data/state/MINNESOTA&#39;) MN_COVIDTRACKER[1].to_csv(&#39;../_data/data_sources/covidtracker/&#39;+date+&#39;-MINNESOTA.csv&#39;) MI_COVIDTRACKER=pd.read_html(&#39;https://covidtracking.com/data/state/MICHIGAN&#39;) MI_COVIDTRACKER[1].to_csv(&#39;../_data/data_sources/covidtracker/&#39;+date+&#39;-MICHIGAN.csv&#39;) . NEW YORK TIMES DATA . #NEW YORK TIMES DATA MASK_NYT=pd.read_csv(&#39;https://raw.githubusercontent.com/nytimes/covid-19-data/master/mask-use/mask-use-by-county.csv&#39;) MASK_NYT.to_csv(&#39;../_data/data_sources/NYT/MASKUSAGE-&#39;+date+&#39;.csv&#39;) CASESDEATHSC_NYT=pd.read_csv(&#39;https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv&#39;) CASESDEATHSC_NYT.to_csv(&#39;../_data/data_sources/NYT/CASES-DEATHS-COUNTY-&#39;+date+&#39;.csv&#39;) CASESDEATHS_NYT=pd.read_csv(&#39;https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv&#39;) CASESDEATHS_NYT.to_csv(&#39;../_data/data_sources/NYT/CASES-DEATHS-STATE-&#39;+date+&#39;.csv&#39;) CASESDEATHSCD_NYT=pd.read_csv(&#39;https://raw.githubusercontent.com/nytimes/covid-19-data/master/live/us-counties.csv&#39;) CASESDEATHSCD_NYT.to_csv(&#39;../_data/data_sources/NYT/CASES-DEATHS-COUNTY-DAILY-&#39;+date+&#39;.csv&#39;) CASESDEATHSD_NYT=pd.read_csv(&#39;https://raw.githubusercontent.com/nytimes/covid-19-data/master/live/us-states.csv&#39;) CASESDEATHSD_NYT.to_csv(&#39;../_data/data_sources/NYT/CASES-DEATHS-STATE-DAILY-&#39;+date+&#39;.csv&#39;) EXDEATHS_NYT=pd.read_csv(&#39;https://raw.githubusercontent.com/nytimes/covid-19-data/master/excess-deaths/deaths.csv&#39;) EXDEATHS_NYT.to_csv(&#39;../_data/data_sources/NYT/EXCESS-DEATHS-CITY-&#39;+date+&#39;.csv&#39;) . LINLAB=pd.read_csv(&#39;https://raw.githubusercontent.com/lin-lab/COVID19-Viz/master/clean_data/rt_table_export.csv&#39;) LINLAB.to_csv(&#39;../_data/data_sources/LINLAB/RTCOUNTYLEVEL-&#39;+date+&#39;.csv&#39;) . wew=requests.get(&#39;https://www.geonames.org/statistics/&#39;) us=pd.read_html(wew.text) us[1].to_csv(&#39;../_data/data_sources/worldCountryPopulations.csv&#39;) . &lt;/div&gt; | | | | | | | .",
            "url": "https://richcastro82.github.io/Notebooks/matrix/2020/08/30/Matrix-Data-Scrapper.html",
            "relUrl": "/matrix/2020/08/30/Matrix-Data-Scrapper.html",
            "date": " • Aug 30, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "KERRY MATRIX",
            "content": "#collapse #IMPORTING LIBRARIES AND DATA FILES import pandas as pd mat=pd.read_csv(&#39;../us_m.csv&#39;) kerry=pd.read_csv(&#39;../kerry.csv&#39;) rt = pd.read_csv(&#39;https://d14wlfuexuxgcm.cloudfront.net/covid/rt.csv&#39;) da = pd.read_csv(&#39;https://covidtracking.com/api/v1/states/daily.csv&#39;) . . #collapse #FORMATING DATA FROM LAST WEEKS MATRIX TO MOVE WEEKLY DATA OVER mat.columns = map(str.lower, mat.columns) col=[&#39;state&#39;,&#39;social index current&#39;,&#39;rt current&#39;,&#39;test increase current&#39;,&#39;tpr current&#39;, &#39;weekly deaths current&#39;,&#39;total deaths current&#39;,&#39;total tests current&#39;] newCol=mat[col] newerCol=newCol.rename(columns={&#39;social index current&#39;:&#39;social index past&#39; ,&#39;rt current&#39;:&#39;rt past&#39; ,&#39;test increase current&#39;:&#39;test increase past&#39;, &#39;tpr current&#39;:&#39;tpr past&#39;, &#39;weekly deaths current&#39;:&#39;weekly deaths past&#39;, &#39;total deaths current&#39;:&#39;total deaths past&#39;, &#39;total tests current&#39;:&#39;total tests past&#39;}) kerry.columns=map(str.lower, kerry.columns) . . #collapse #CLEANING THE RTLIVE DATA today=&#39;2020-08-03&#39; rtCleaned = rt[rt[&#39;date&#39;]==today] rtColumns = [&#39;date&#39;, &#39;region&#39;, &#39;mean&#39;] rtCleaned = rtCleaned[rtColumns] rtCleaned = rtCleaned.rename(columns = {&#39;region&#39;:&#39;state&#39;}) rtCleaned = rtCleaned.sort_values(&#39;state&#39;, ascending=True) . . #collapse #CLEANING THE DAILY COVID DATA dateRange=&#39;20200803&#39; dailyColumns = [&#39;date&#39;, &#39;state&#39;, &#39;death&#39;, &#39;positiveIncrease&#39;, &#39;totalTestResultsIncrease&#39;, &#39;deathIncrease&#39;] dailyData = da[dailyColumns] dailyData = dailyData.sort_values(&#39;state&#39;, ascending=True) dailyCleaned = dailyData[dailyData[&#39;date&#39;].astype(str)==dateRange] . . #collapse #MERGING THE DATASETS TOGETHER mergef=pd.merge(kerry, rtCleaned, on=&#39;state&#39;) merget=pd.merge(mergef, dailyCleaned, on=&#39;state&#39;) merger=pd.merge(merget, newerCol, on=&#39;state&#39;) . . #SHOW THE LOCATIONS FOR CLIENT kerry . state population . 0 AL | 4903185 | . 1 AR | 3017804 | . 2 CA | 39512223 | . 3 FL | 21477737 | . 4 GA | 10617423 | . 5 IA | 3155070 | . 6 IL | 12671821 | . 7 IN | 6732219 | . 8 KS | 2913314 | . 9 MD | 6045680 | . 10 ME | 1344212 | . 11 MN | 5639632 | . 12 MO | 6137428 | . 13 MS | 2976149 | . 14 NJ | 8882190 | . 15 NY | 19453561 | . 16 OH | 11689100 | . 17 TN | 6829174 | . 18 TX | 28995881 | . 19 VA | 8535519 | . 20 WA | 7614893 | . 21 WI | 5822434 | . #SHOW CLIP OF THE RT DATA rtCleaned.head(3) . date state mean . 8000 2020-08-03 | AK | 1.045968 | . 3675 2020-08-03 | AL | 1.037615 | . 4948 2020-08-03 | AR | 1.032516 | . #SHOW CLIP OF THE DAILY DATA dailyCleaned.head(3) . date state death positiveIncrease totalTestResultsIncrease deathIncrease . 112 20200803 | AK | 25.0 | 80 | 2717 | 1 | . 113 20200803 | AL | 1633.0 | 1217 | 7981 | 6 | . 114 20200803 | AR | 475.0 | 1424 | 12819 | 17 | . #SHOW CLIP OF THE PAST DATA newerCol.head(3) . state social index past rt past test increase past tpr past weekly deaths past total deaths past total tests past . 0 AL | 22 | 1.111944 | 11546 | 21% | 142 | 1633 | 56092 | . 1 AR | 76 | 1.037065 | 5150 | 12% | 67 | 475 | 42509 | . 2 CA | 22 | 0.970088 | 54351 | 6% | 943 | 9388 | 888118 | . #SHOW THE MERGED DATA merger . state population date_x mean date_y death positiveIncrease totalTestResultsIncrease deathIncrease social index past rt past test increase past tpr past weekly deaths past total deaths past total tests past . 0 AL | 4903185 | 2020-08-03 | 1.037615 | 20200803 | 1633.0 | 1217 | 7981 | 6 | 22 | 1.111944 | 11546 | 21% | 142 | 1633 | 56092 | . 1 AR | 3017804 | 2020-08-03 | 1.032516 | 20200803 | 475.0 | 1424 | 12819 | 17 | 76 | 1.037065 | 5150 | 12% | 67 | 475 | 42509 | . 2 CA | 39512223 | 2020-08-03 | 0.887432 | 20200803 | 9388.0 | 5739 | 148721 | 32 | 22 | 0.970088 | 54351 | 6% | 943 | 9388 | 888118 | . 3 FL | 21477737 | 2020-08-03 | 0.965805 | 20200803 | 7279.0 | 4752 | 31801 | 73 | 85 | 0.986019 | 59137 | 18% | 1230 | 7279 | 321301 | . 4 GA | 10617423 | 2020-08-03 | 0.953591 | 20200803 | 3842.0 | 2258 | 21761 | 2 | 22 | 0.953783 | 24592 | 13% | 333 | 3842 | 193438 | . 5 IA | 3155070 | 2020-08-03 | 0.986369 | 20200803 | 882.0 | 349 | 2357 | 6 | 16 | 1.010162 | 3287 | 10% | 49 | 882 | 31630 | . 6 IL | 12671821 | 2020-08-03 | 1.079520 | 20200803 | 7723.0 | 1298 | 28475 | 9 | 44 | 1.092876 | 10625 | 4% | 115 | 7723 | 264702 | . 7 IN | 6732219 | 2020-08-03 | 1.005326 | 20200803 | 2980.0 | 576 | 6439 | 5 | 54 | 1.001587 | 5526 | 8% | 74 | 2980 | 67691 | . 8 KS | 2913314 | 2020-08-03 | 1.062584 | 20200803 | 365.0 | 1064 | 9332 | 7 | 46 | 1.071201 | 2704 | 12% | 30 | 365 | 22903 | . 9 MD | 6045680 | 2020-08-03 | 1.031896 | 20200803 | 3523.0 | 870 | 15851 | 8 | 45 | 1.047616 | 6268 | 6% | 76 | 3523 | 105119 | . 10 ME | 1344212 | 2020-08-03 | 0.935590 | 20200803 | 124.0 | 12 | 2071 | 1 | 45 | 0.975832 | 138 | 1% | 5 | 124 | 16704 | . 11 MN | 5639632 | 2020-08-03 | 1.103790 | 20200803 | 1656.0 | 613 | 13663 | 2 | 45 | 1.074376 | 4757 | -5% | 40 | 1656 | -98722 | . 12 MO | 6137428 | 2020-08-03 | 1.166522 | 20200803 | 1255.0 | 1047 | 10481 | 2 | 1 | 1.220294 | 9837 | 14% | 54 | 1255 | 71044 | . 13 MS | 2976149 | 2020-08-03 | 1.071332 | 20200803 | 1711.0 | 572 | 572 | 8 | 13 | 1.061724 | 8168 | 23% | 210 | 1711 | 35120 | . 14 NJ | 8882190 | 2020-08-03 | 0.975566 | 20200803 | 15846.0 | 264 | 18702 | 10 | 15 | 0.965851 | 2802 | 2% | 42 | 15846 | 180739 | . 15 NY | 19453561 | 2020-08-03 | 0.963728 | 20200803 | 25172.0 | 545 | 51839 | 2 | 52 | 0.941746 | 4499 | 1% | 55 | 25172 | 455625 | . 16 OH | 11689100 | 2020-08-03 | 0.941189 | 20200803 | 3539.0 | 932 | 17997 | 10 | 64 | 0.918456 | 8786 | 5% | 195 | 3539 | 191445 | . 17 TN | 6829174 | 2020-08-03 | 0.986842 | 20200803 | 1092.0 | 1009 | 12235 | 19 | 15 | 0.980140 | 14147 | 9% | 114 | 1092 | 163081 | . 18 TX | 28995881 | 2020-08-03 | 0.957834 | 20200803 | 7016.0 | 11529 | 86807 | 179 | 35 | 0.933380 | 56091 | 14% | 1303 | 7016 | 405704 | . 19 VA | 8535519 | 2020-08-03 | 1.096200 | 20200803 | 2218.0 | 1324 | 15082 | 0 | 85 | 1.023291 | 7034 | 6% | 136 | 2218 | 115897 | . 20 WA | 7614893 | 2020-08-03 | 1.091667 | 20200803 | 1596.0 | 632 | 6752 | 4 | 25 | 1.012360 | 5538 | 6% | 95 | 57 | 88933 | . 21 WI | 5822434 | 2020-08-03 | 0.918711 | 20200803 | 956.0 | 411 | 7180 | 1 | 26 | 0.985503 | 6120 | 7% | 56 | 1596 | 93650 | .",
            "url": "https://richcastro82.github.io/Notebooks/matrix/2020/08/30/Kerry_Matrix_2.0.html",
            "relUrl": "/matrix/2020/08/30/Kerry_Matrix_2.0.html",
            "date": " • Aug 30, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "KELLOGGS MATRIX",
            "content": "#collapse-hide #IMPORT LIBRARIES FROM PYTHON import pandas as pd pd.options.display.max_rows = 2800 . . #collapse-hide #IMPORT DATA SETS FROM TRUSTED SOURCES #US CENSUS DATA FROM - censusData = pd.read_csv(&#39;../_data/cen.csv&#39;) censusData.columns=map(str.lower, censusData.columns) #COUNTY MASK USAGE FROM - maskData = pd.read_csv(&#39;../_data/maskbycounty.csv&#39;) maskData.columns=map(str.lower, maskData.columns) #CLIENT LOCATION DATA locations=pd.read_csv(&#39;../_data/kellogg_locations.csv&#39;) locations loc=[&#39;state&#39;, &#39;county&#39;] showLocs=locations[loc] showLocs.set_index(&#39;state&#39;, inplace=True) print(&#39;These are the US Locations for: Kelloggs&#39;) showLocs . . #collapse-hide #IMPORT LIBRARIES import numpy as np from matplotlib import pyplot as plt from mpl_toolkits.basemap import Basemap cities = pd.read_csv(&#39;../_data/client_locations/kelloggs.csv&#39;) lat = cities[&#39;lat&#39;].values lon = cities[&#39;long_&#39;].values population = cities[&#39;active&#39;].values area = cities[&#39;tee&#39;].values #collapse-hide fig = plt.figure(figsize=(18, 10)) m = Basemap(llcrnrlon=-119,llcrnrlat=22,urcrnrlon=-64,urcrnrlat=49, projection=&#39;lcc&#39;, resolution=&#39;l&#39;, lat_1=33,lat_2=45,lon_0=-95) m.shadedrelief() m.drawcoastlines(color=&#39;gray&#39;) m.drawcountries(color=&#39;gray&#39;) m.drawstates(color=&#39;gray&#39;) m.drawcounties(color=&#39;gray&#39;) m.scatter(lon, lat, latlon=True, c=np.log10(population), s=area, cmap=&#39;Reds&#39;, alpha=1) plt.title(&quot;Kelloggs Locations&quot;) plt.colorbar(label=r&#39;Covid Cases(Active)&#39;) plt.clim(3, 7) . . #collapse-hide #RTLIVE DATA rt=pd.read_csv(&#39;../_data/rt.csv&#39;) #TN DATA IMPORT tn=pd.read_csv(&#39;../_data/tn.csv&#39;) tn.columns=map(str.lower, tn.columns) #OH DATA IMPORT oh=pd.read_csv(&#39;../_data/ohio.csv&#39;) oh.columns=map(str.lower, oh.columns) #FL DATA IMPORT fl=pd.read_csv(&#39;../_data/fl.csv&#39;) fl.columns=map(str.lower, fl.columns) #RT DATA CLEANING rt=rt.rename(columns={&#39;region&#39;:&#39;st&#39;}) rtC=[&#39;date&#39;, &#39;st&#39;, &#39;mean&#39;] rta=rt[rtC] #CLIENT AND RT DATA MERGE LocationRT=pd.merge(locations, rta, on=&#39;st&#39;) Location=LocationRT[LocationRT[&#39;date&#39;]==&#39;8/2/2020&#39;] #CENSUS DATA CLEANING cenC=[&#39;fips&#39;,&#39;popestimate2019&#39;] cen=censusData[cenC] #CLIENT AND CENSUS DATA MERGE locationCen=pd.merge(Location.astype(str), cen, on=&#39;fips&#39;) locationMask=pd.merge(locationCen, maskData.astype(str), on=&#39;fips&#39;) matrixReport=locationMask locations . . #collapse-hide tn=tn.rename(columns={&#39;state&#39;:&#39;st&#39;, &#39;test_pos&#39;:&#39;testP&#39;, &#39;test_neg&#39;:&#39;testN&#39;, &#39;test_tot&#39;:&#39;testT&#39;, &#39;test_new&#39;:&#39;testNew&#39;, &#39;cases_confirmed&#39;:&#39;cases&#39;, &#39;new_cases_confirmed&#39;:&#39;casesNewCf&#39;, &#39;cases_probable&#39;:&#39;casesP&#39;, &#39;cases_new_probable&#39;:&#39;casesNP&#39;, &#39;cases_tot&#39;:&#39;caseT&#39;, &#39;cases_new&#39;:&#39;caseNew&#39;, &#39;hospitalized_tot&#39;:&#39;hospT&#39;, &#39;hospitalized_new&#39;:&#39;hospN&#39;, &#39;recov_tot&#39;:&#39;recT&#39;, &#39;recov_new&#39;:&#39;recN&#39;, &#39;deaths_tot&#39;:&#39;deathsT&#39;, &#39;deaths_new&#39;:&#39;deathsNew&#39;, &#39;active_tot&#39;:&#39;actT&#39;, &#39;active_new&#39;:&#39;actNew&#39;}) tnCol=[&#39;date&#39;, &#39;st&#39;, &#39;county&#39;, &#39;testP&#39;, &#39;testN&#39;, &#39;testT&#39;,&#39;testNew&#39;, &#39;cases&#39;, &#39;casesNewCf&#39;,&#39;casesP&#39;, &#39;casesNP&#39;, &#39;caseT&#39;, &#39;caseNew&#39;, &#39;hospT&#39;,&#39;hospN&#39;, &#39;recT&#39;, &#39;recN&#39;, &#39;deathsT&#39;, &#39;deathsNew&#39;, &#39;actT&#39;, &#39;actNew&#39;] tnc=tn[tnCol] tnc . . #collapse-hide fl=fl.rename(columns={&#39;cases_c&#39;:&#39;caseT&#39;, &#39;test_t&#39;:&#39;testT&#39;, &#39;test_n&#39;:&#39;testN&#39;, &#39;test_p&#39;:&#39;testP&#39;, &#39;deaths_tot&#39;:&#39;deathsT&#39;}) flCol=[&#39;county&#39;, &#39;state&#39;, &#39;caseT&#39;, &#39;testT&#39;, &#39;testN&#39;, &#39;testP&#39;, &#39;deathsT&#39;] flc=fl[flCol] . . #collapse-hide ohCol=[&#39;case count&#39;, &#39;death count&#39;, &#39;hospitalized count&#39;, &#39;fips&#39;] ohC=oh[ohCol] ohC=ohC.rename(columns={&#39;case count&#39;:&#39;caseT&#39;, &#39;death count&#39;:&#39;deathT&#39;, &#39;hospitalized count&#39;:&#39;hospT&#39;}) . . #collapse-hide matrixMix=pd.merge(matrixReport, ohC.astype(str), on=&#39;fips&#39;, how=&#39;left&#39;) flc=flc.rename(columns={&#39;state&#39;:&#39;st&#39;}) matrixM=pd.merge(matrixMix, flc, on=[&#39;county&#39;, &#39;st&#39;], how=&#39;left&#39;) matrixM.head(1) . . #collapse-hide tnc.columns . . #collapse-hide mat=pd.merge(matrixM.astype(str)[pd.notnull], tnc.astype(str)[pd.notnull], on=[&#39;st&#39;, &#39;county&#39;, &#39;deathsT&#39;, &#39;testT&#39;, &#39;testN&#39;, &#39;hospT&#39;], how=&#39;left&#39;) pd.options.display.max_rows = 2800 pd.options.display.max_columns = 2800 mat . . #collapse-hide #RT DATA FROM - D=pd.read_csv(&#39;../_data/rttestcounty.csv&#39;) countyData = pd.read_csv(&#39;../_data/isee.csv&#39;) rtData = pd.read_csv(&#39;https://d14wlfuexuxgcm.cloudfront.net/covid/rt.csv&#39;) #CLEAN UP DATA AND STANDARDIZE THE COLUMNS ACol=[ &#39;uid&#39;, &#39;date&#39;, &#39;resolution&#39;, &#39;date_lag&#39;, &#39;Rt_plot&#39;, &#39;Rt_upr&#39;, &#39;Rt_lwr&#39;, &#39;Rt_loess_fit&#39;, &#39;Rt_loess_lwr&#39;, &#39;Rt_loess_upr&#39;, &#39;positiveIncrease&#39;, &#39;positive&#39;, &#39;positive_7day&#39;, &#39;positive_percapita&#39;, &#39;positiveIncr_percapita&#39;, &#39;deathIncrease&#39;, &#39;death&#39;, &#39;death_percapita&#39;, &#39;deathIncr_percapita&#39;] As=countyData[ACol] pCol=[&#39;fips&#39;, &#39;POPESTIMATE2019&#39;] censusDataCleaned=censusData[pCol] #KELLOGGS LOCATIONS clientLocations=pd.read_csv(&#39;../_data/kellogg_locations.csv&#39;) fCol=[&#39;uid&#39;, &#39;fips&#39;, &#39;state&#39;, &#39;county&#39;] clientDataCleaned=clientLocations[fCol] clientDataCleaned mergeClientCensus=pd.merge(censusDataCleaned, clientDataCleaned.astype(str), on =&quot;fips&quot;) mergeData=mergeClientCensus.sort_values(&#39;state&#39;) md=pd.merge(mergeData, D.astype(str), on=&#39;fips&#39;) mn=md.sort_values(&#39;state&#39;) UT=pd.merge(mergeData, As.astype(str), on=&#39;uid&#39;) today = &#39;08/01/2020&#39; UTT = UT[UT[&#39;date&#39;]==today] AwA=pd.merge(As.astype(str), mergeData, on=&#39;uid&#39;, ) AwCol=[ &#39;state&#39;, &#39;county&#39;, &#39;date&#39;, &#39;resolution&#39;, &#39;Rt_plot&#39;, &#39;Rt_upr&#39;, &#39;Rt_lwr&#39;, &#39;Rt_loess_fit&#39;, &#39;Rt_loess_lwr&#39;, &#39;Rt_loess_upr&#39;, &#39;positiveIncrease&#39;, &#39;positive&#39;, &#39;positive_7day&#39;, &#39;positive_percapita&#39;, &#39;positiveIncr_percapita&#39;, &#39;deathIncrease&#39;, &#39;death&#39;, &#39;death_percapita&#39;, &#39;deathIncr_percapita&#39;, &#39;POPESTIMATE2019&#39;, &#39;fips&#39; ] AwCleaned = AwA[AwCol] ATT=pd.merge(AwCleaned, maskData.astype(str), on=&#39;fips&#39;) pd.options.display.max_rows = 2800 ATCol=[&#39;state&#39;, &#39;county&#39;, &#39;date&#39;, &#39;Rt_plot&#39;, &#39;positiveIncrease&#39;, &#39;positive&#39;, &#39;positive_7day&#39;, &#39;positive_percapita&#39;, &#39;positiveIncr_percapita&#39;, &#39;deathIncrease&#39;, &#39;death&#39;, &#39;death_percapita&#39;, &#39;deathIncr_percapita&#39;, &#39;POPESTIMATE2019&#39;, &#39;NEVER&#39;, &#39;RARELY&#39;, &#39;SOMETIMES&#39;, &#39;FREQUENTLY&#39;, &#39;ALWAYS&#39;] ATR=ATT[ATCol] ATY = ATR[ATR[&#39;date&#39;]==&#39;7/18/2020&#39;] . .",
            "url": "https://richcastro82.github.io/Notebooks/matrix/2020/08/30/Kelloggs_Matrix.html",
            "relUrl": "/matrix/2020/08/30/Kelloggs_Matrix.html",
            "date": " • Aug 30, 2020"
        }
        
    
  
    
  
    
        ,"post5": {
            "title": "US COUNTY LEVEL MAP",
            "content": "THIS IS A TEST OF THE MATPLOTLIB MAPPING SYSTEM. . #collapse-hide client=input(&#39;Client Name: &#39;) client=client.lower() client . . Client Name: kelloggs . &#39;kelloggs&#39; . #plot deaths . #plot cases . #plot testing . #collapse-hide #IMPORT LIBRARIES import pandas as pd import numpy as np from matplotlib import pyplot as plt from mpl_toolkits.basemap import Basemap cities = pd.read_csv(&#39;../_data/client_locations/&#39; + client + &#39;Cleaned.csv&#39;) lat = cities[&#39;lat_&#39;].values lon = cities[&#39;long&#39;].values population = cities[&#39;active&#39;].values area = cities[&#39;tee&#39;].values . . #collapse-hide fig = plt.figure(figsize=(18, 10)) m = Basemap(llcrnrlon=-119,llcrnrlat=22,urcrnrlon=-64,urcrnrlat=49, projection=&#39;lcc&#39;, resolution=&#39;l&#39;, lat_1=33,lat_2=45,lon_0=-95) m.shadedrelief() m.drawcoastlines(color=&#39;gray&#39;) m.drawcountries(color=&#39;gray&#39;) m.drawstates(color=&#39;gray&#39;) m.drawcounties(color=&#39;gray&#39;) m.scatter(lon, lat, latlon=True, c=np.log10(population), s=area, cmap=&#39;Reds&#39;, alpha=1) client=client.upper() plt.title(client + &quot; Locations&quot;) plt.colorbar(label=r&#39;Covid Cases(Active)&#39;) plt.clim(3, 7) . . #collapse-hide import warnings warnings.filterwarnings(&#39;ignore&#39;) rt=pd.read_csv(&#39;../_data/_misc/rt.csv&#39;) rta=rt[rt[&#39;region&#39;]==&#39;AR&#39;] rta[&#39;date&#39;] = pd.to_datetime(rta[&#39;date&#39;]) rta.set_index(&#39;date&#39;, inplace=True) rta=rta.sort_values(&#39;date&#39;, ascending=False) rt2=pd.read_csv(&#39;../_data/_misc/rt.csv&#39;) rta2=rt[rt2[&#39;region&#39;]==&#39;NY&#39;] rta2[&#39;date&#39;] = pd.to_datetime(rta2[&#39;date&#39;]) rta2.set_index(&#39;date&#39;, inplace=True) rta2=rta2.sort_values(&#39;date&#39;, ascending=False) rt3=pd.read_csv(&#39;../_data/_misc/rt.csv&#39;) rta3=rt[rt3[&#39;region&#39;]==&#39;NJ&#39;] rta3[&#39;date&#39;] = pd.to_datetime(rta3[&#39;date&#39;]) rta3.set_index(&#39;date&#39;, inplace=True) rta3=rta3.sort_values(&#39;date&#39;, ascending=False) rt4=pd.read_csv(&#39;../_data/_misc/rt.csv&#39;) rta4=rt[rt4[&#39;region&#39;]==&#39;WA&#39;] rta4[&#39;date&#39;] = pd.to_datetime(rta4[&#39;date&#39;]) rta4.set_index(&#39;date&#39;, inplace=True) rta4=rta4.sort_values(&#39;date&#39;, ascending=False) rt5=pd.read_csv(&#39;../_data/_misc/rt.csv&#39;) rta5=rt[rt5[&#39;region&#39;]==&#39;TN&#39;] rta5[&#39;date&#39;] = pd.to_datetime(rta5[&#39;date&#39;]) rta5.set_index(&#39;date&#39;, inplace=True) rta5=rta5.sort_values(&#39;date&#39;, ascending=False) . . #collapse-hide rta2[&#39;mean&#39;].plot() rta5[&#39;mean&#39;].plot() rta3[&#39;mean&#39;].plot() . . &lt;matplotlib.axes._subplots.AxesSubplot at 0x2290036c5e0&gt; .",
            "url": "https://richcastro82.github.io/Notebooks/matrix/2020/08/30/Client-Location-Map-Code.html",
            "relUrl": "/matrix/2020/08/30/Client-Location-Map-Code.html",
            "date": " • Aug 30, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "BUILD OUT CLIENT LOCATION FILES",
            "content": "THIS MODULE WILL TAKE A EXCEL FILE WITH JUST THE COUNTY AND STATE OF ANY CLIENT LOCATIONS AND BUILD OUT AN EXCEL FILE THAT INCLUDES THE FIPS CODE, POPULATION, LAT/LONG POSITIONS FOR MAP BUILDING, AND INDEXES THE TABLE ON THE FIP COLUMN . #collapse-hide client=input(&#39;Client Name : &#39;) print(&#39;PULLING STATE AND COUNTY LOCATIONS FOR: &#39; + client.upper()) clientLocations=pd.read_csv(&#39;../_data/client_locations/&#39; + client + &#39;.csv&#39;) clientLocations.columns = map(str.lower, clientLocations.columns) clientLocations . . Client Name : pepsi2 PULLING STATE AND COUNTY LOCATIONS FOR: PEPSI2 . state county . 0 Ohio | Summit | . 1 Alabama | Madison | . 2 New York | Onondaga | . 3 Virginia | Roanoke | . 4 Pennsylvania | Lackawanna | . 5 Illinois | Champaign | . 6 Indiana | Marion | . 7 Wisconsin | Dane | . #collapse-hide cenLat=pd.read_csv(&#39;../_data/Data_Sources/Census/Geo-Fips.csv&#39;) cenLat . . fips county state country lat long combined_key . 0 45001 | Abbeville | South Carolina | US | 34.223334 | -82.461707 | Abbeville, South Carolina, US | . 1 22001 | Acadia | Louisiana | US | 30.295065 | -92.414197 | Acadia, Louisiana, US | . 2 51001 | Accomack | Virginia | US | 37.767072 | -75.632346 | Accomack, Virginia, US | . 3 16001 | Ada | Idaho | US | 43.452658 | -116.241552 | Ada, Idaho, US | . 4 19001 | Adair | Iowa | US | 41.330756 | -94.471059 | Adair, Iowa, US | . ... ... | ... | ... | ... | ... | ... | ... | . 3239 78 | NaN | Virgin Islands | US | 18.335800 | -64.896300 | Virgin Islands, US | . 3240 90048 | Unassigned | Texas | US | NaN | NaN | Unassigned, Texas, US | . 3241 90023 | Unassigned | Maine | US | NaN | NaN | Unassigned, Maine, US | . 3242 16061 | Lewis | Idaho | US | 46.233153 | -116.434146 | Lewis, Idaho, US | . 3243 41069 | Wheeler | Oregon | US | 44.726982 | -120.028143 | Wheeler, Oregon, US | . 3244 rows × 7 columns . #collapse-hide clm=pd.merge(cenLat, clientLocations, on=[&#39;state&#39;, &#39;county&#39;]) clmCol=[ &#39;fips&#39;, &#39;country&#39;, &#39;state&#39;, &#39;county&#39;, &#39;lat&#39;, &#39;long&#39;] clientDataCleaned=clm[clmCol] clientDataCleaned . . fips country state county lat long . 0 17019 | US | Illinois | Champaign | 40.139194 | -88.200466 | . 1 55025 | US | Wisconsin | Dane | 43.066016 | -89.417338 | . 2 42069 | US | Pennsylvania | Lackawanna | 41.435647 | -75.603792 | . 3 1089 | US | Alabama | Madison | 34.763271 | -86.550696 | . 4 18097 | US | Indiana | Marion | 39.781636 | -86.138263 | . 5 36067 | US | New York | Onondaga | 43.004919 | -76.199712 | . 6 51161 | US | Virginia | Roanoke | 37.268658 | -80.063968 | . 7 39153 | US | Ohio | Summit | 41.124647 | -81.531231 | . #collapse-hide cen=pd.read_csv(&#39;../_data/Data_Sources/Census/Census_2019.csv&#39;) cCol=[&#39;state&#39;, &#39;county&#39;, &#39;pop19&#39;] censusData=cen[cCol] censusData . . state county pop19 . 0 Alabama | Autauga | 55869 | . 1 Alabama | Baldwin | 223234 | . 2 Alabama | Barbour | 24686 | . 3 Alabama | Bibb | 22394 | . 4 Alabama | Blount | 57826 | . ... ... | ... | ... | . 3137 Wyoming | Sweetwater | 42343 | . 3138 Wyoming | Teton | 23464 | . 3139 Wyoming | Uinta | 20226 | . 3140 Wyoming | Washakie | 7805 | . 3141 Wyoming | Weston | 6927 | . 3142 rows × 3 columns . #collapse-hide ClientCensusCleaned=pd.merge(clientDataCleaned, censusData, on=[&#39;state&#39;,&#39;county&#39;], how=&#39;left&#39;) ClientCensusCleaned.set_index(&#39;fips&#39;, inplace=True) clientDataCleaned.shape . . (8, 6) . #collapse-hide print(&#39;THIS IS THE ORIGINAL LOCATIONS FILE FOR:&#39; + client) clientLocations . . THIS IS THE ORIGINAL LOCATIONS FILE FOR:pepsi2 . state county . 0 Ohio | Summit | . 1 Alabama | Madison | . 2 New York | Onondaga | . 3 Virginia | Roanoke | . 4 Pennsylvania | Lackawanna | . 5 Illinois | Champaign | . 6 Indiana | Marion | . 7 Wisconsin | Dane | . #collapse-hide print(&#39;THIS IS THE LAT/LONG AND FIPS CODES DATASET&#39;) cenLat.head(3) . . THIS IS THE LAT/LONG AND FIPS CODES DATASET . fips county state country lat long combined_key . 0 45001 | Abbeville | South Carolina | US | 34.223334 | -82.461707 | Abbeville, South Carolina, US | . 1 22001 | Acadia | Louisiana | US | 30.295065 | -92.414197 | Acadia, Louisiana, US | . 2 51001 | Accomack | Virginia | US | 37.767072 | -75.632346 | Accomack, Virginia, US | . #collapse-hide print(&#39;THIS IS THE CENSUS POPULATION DATASET&#39;) censusData.head(3) . . THIS IS THE CENSUS POPULATION DATASET . state county pop19 . 0 Alabama | Autauga | 55869 | . 1 Alabama | Baldwin | 223234 | . 2 Alabama | Barbour | 24686 | . #collapse-hide print(&#39;THIS IS THE NEW CLIENT LOCATIONS FILE&#39;) ClientCensusCleaned . . THIS IS THE NEW CLIENT LOCATIONS FILE . country state county lat long pop19 . fips . 17019 US | Illinois | Champaign | 40.139194 | -88.200466 | 209689 | . 55025 US | Wisconsin | Dane | 43.066016 | -89.417338 | 546695 | . 42069 US | Pennsylvania | Lackawanna | 41.435647 | -75.603792 | 209674 | . 1089 US | Alabama | Madison | 34.763271 | -86.550696 | 372909 | . 18097 US | Indiana | Marion | 39.781636 | -86.138263 | 964582 | . 36067 US | New York | Onondaga | 43.004919 | -76.199712 | 460528 | . 51161 US | Virginia | Roanoke | 37.268658 | -80.063968 | 94186 | . 39153 US | Ohio | Summit | 41.124647 | -81.531231 | 541013 | . #collapse-hide ClientCensusCleaned.to_csv(&#39;../_data/client_Locations/&#39; + client + &#39;Cleaned.csv&#39;) print(&#39;MERGED THE ORIGINAL &#39; + client + &#39; LOCATIONS FILE AND ADDED CENSUS DATA, FIPS CODES, AND LAT/LONG&#39;) print (&#39;NEW FILE CAN BE FOUND AT: _DATA/CLIENT_LOCATIONS/&#39; + client + &#39;Cleaned.csv&#39;) . . MERGED THE ORIGINAL pepsi2 LOCATIONS FILE AND ADDED CENSUS DATA, FIPS CODES, AND LAT/LONG NEW FILE CAN BE FOUND AT: _DATA/CLIENT_LOCATIONS/pepsi2Cleaned.csv .",
            "url": "https://richcastro82.github.io/Notebooks/matrix/2020/08/30/Build-Client-Location-Files.html",
            "relUrl": "/matrix/2020/08/30/Build-Client-Location-Files.html",
            "date": " • Aug 30, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "A&W CANADA DATASET",
            "content": "#IMPORTING EXTERNAL LIBRARIES AND SETTING THE DATE AND WEEK RANGE. import pandas as pd import datetime import numpy as np from pivottablejs import pivot_ui date=datetime.datetime.now().strftime(&quot;%Y-%m-%d&quot;) print (date) #SET 7 DAYS TIMEFRAME FROM TODAYS DATE weekly=pd.date_range(end=date, periods=7).strftime(&quot;%Y-%m-%d&quot;) biweekly=pd.date_range(end=date, periods=14) print(weekly) print (biweekly) df_cl.columns . 2020-08-30 Index([&#39;2020-08-24&#39;, &#39;2020-08-25&#39;, &#39;2020-08-26&#39;, &#39;2020-08-27&#39;, &#39;2020-08-28&#39;, &#39;2020-08-29&#39;, &#39;2020-08-30&#39;], dtype=&#39;object&#39;) DatetimeIndex([&#39;2020-08-17&#39;, &#39;2020-08-18&#39;, &#39;2020-08-19&#39;, &#39;2020-08-20&#39;, &#39;2020-08-21&#39;, &#39;2020-08-22&#39;, &#39;2020-08-23&#39;, &#39;2020-08-24&#39;, &#39;2020-08-25&#39;, &#39;2020-08-26&#39;, &#39;2020-08-27&#39;, &#39;2020-08-28&#39;, &#39;2020-08-29&#39;, &#39;2020-08-30&#39;], dtype=&#39;datetime64[ns]&#39;, freq=&#39;D&#39;) . Index([&#39;region&#39;, &#39;reg_pop&#39;, &#39;prov_pop&#39;], dtype=&#39;object&#39;) . #IMPORTING DATASETS from datetime import datetime df_ca= pd.read_csv(&#39;../_data/Data_Sources/Canada/hrcases.csv&#39;) df_cl=pd.read_csv(&#39;../_data/client_locations/anw_canada.csv&#39;) #canada_Population=pd.read_csv(&#39;../_data/data_resources/canada/caCensus.csv&#39;) df_cl=df_cl.set_index(&#39;province&#39;) df_ca.rename(columns={&#39;health_region&#39;:&#39;region&#39;, &#39;date_report&#39;:&#39;date&#39;}, inplace=True) df_ca[&#39;date&#39;] = df_ca[&#39;date&#39;].astype(&#39;datetime64&#39;) df_ca.set_index(&#39;date&#39;, inplace=True) df_ca . KeyError Traceback (most recent call last) &lt;ipython-input-89-4ad7350e31fe&gt; in &lt;module&gt; 9 df_ca[&#39;date&#39;] = df_ca[&#39;date&#39;].astype(&#39;datetime64&#39;) 10 df_ca.set_index(&#39;date&#39;, inplace=True) &gt; 11 df_ca[[&#39;date&#39;]]==&#39;2020-01-25&#39; C: Users anaconda3 envs USAcovidMAP lib site-packages pandas core frame.py in __getitem__(self, key) 2804 if is_iterator(key): 2805 key = list(key) -&gt; 2806 indexer = self.loc._get_listlike_indexer(key, axis=1, raise_missing=True)[1] 2807 2808 # take() does not accept boolean indexers C: Users anaconda3 envs USAcovidMAP lib site-packages pandas core indexing.py in _get_listlike_indexer(self, key, axis, raise_missing) 1550 keyarr, indexer, new_indexer = ax._reindex_non_unique(keyarr) 1551 -&gt; 1552 self._validate_read_indexer( 1553 keyarr, indexer, o._get_axis_number(axis), raise_missing=raise_missing 1554 ) C: Users anaconda3 envs USAcovidMAP lib site-packages pandas core indexing.py in _validate_read_indexer(self, key, indexer, axis, raise_missing) 1638 if missing == len(indexer): 1639 axis_name = self.obj._get_axis_name(axis) -&gt; 1640 raise KeyError(f&#34;None of [{key}] are in the [{axis_name}]&#34;) 1641 1642 # We (temporarily) allow for some missing keys with .loc, except in KeyError: &#34;None of [Index([&#39;date&#39;], dtype=&#39;object&#39;)] are in the [columns]&#34; . #MERGING DATASETS print (df_ca.columns) print(df_cl.columns) print (df_cl.shape) print(df_ca.shape) #client locations and add population data to them. #merge clientCleaned with canada data #sort the dataset by the culmulative and then the county #print the dataset and save it the client/dataset folder with a datestamp . #EXPORTING WEEKLY REPORT #FIGURE OUT HOW TO SOMEHOW MATCH THE DATING TO THE WEIRDNESS IN THE FILE. #SAVE THE FILE TO THE DATA FOLDER WITH A DATE STAMP . #EXPORTING DAILY REPORT #SAVE THE DAILY REPORT TO DATA FOLDER WITH A DATE STAMP . REPLACED SOME COUNTIES TO FILL DATA . #REPLACED SOME LOCATIONS BUT THERE IS A COLUMN TO INDICATE IT. .",
            "url": "https://richcastro82.github.io/Notebooks/matrix/2020/08/30/A&W-CANADA-DATASET-BUILDER.html",
            "relUrl": "/matrix/2020/08/30/A&W-CANADA-DATASET-BUILDER.html",
            "date": " • Aug 30, 2020"
        }
        
    
  
    
        ,"post8": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://richcastro82.github.io/Notebooks/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This is where you put the contents of your About page. Like all your pages, it’s in Markdown format. . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://richcastro82.github.io/Notebooks/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://richcastro82.github.io/Notebooks/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}