{
  
    
        "post0": {
            "title": "PEPSI MATRIX",
            "content": "#IMPORT LIBRARIES AND DATASETS import pandas as pd pepsiLocations=pd.read_csv(&#39;../_data/pepsi_locations.csv&#39;) rt=pd.read_csv(&#39;../_data/rt.csv&#39;) cen=pd.read_csv(&#39;../_data/cen.csv&#39;) rt.columns=map(str.lower, rt.columns) rt=rt.rename(columns={&#39;region&#39;:&#39;state&#39;}) rtCol=[&#39;date&#39;, &#39;state&#39;, &#39;mean&#39;] rta=rt[rtCol] cen.columns=map(str.lower, cen.columns) cenCol=[&#39;fips&#39;, &#39;stname&#39;,&#39;popestimate2019&#39;] cena=cen[cenCol] cena=cena.rename(columns={&#39;stname&#39;:&#39;state&#39;, &#39;ctyname&#39;:&#39;city&#39;, &#39;popestimate2019&#39;:&#39;pop&#39;}) rta=rta.rename(columns={&#39;state&#39;:&#39;st&#39;}) . pepsiLocations.head() . uid fips country facility state st address city county . 0 8405031 | 5031 | USA | Jonesboro, AR | Arkansas | AR | 2810 Quality Way | Jonesboro | Craighead | . 1 8404021 | 4021 | USA | Casa Grande, AZ (Frito Lay) | Azizona | AZ | 1450 W Maricopa Hwy | Casa Grande | Pinal | . 2 8406029 | 6029 | USA | Bakersfield, CA (Frito Lay) | California | CA | 28801 Highway 58 | Bakersfield | Kern | . 3 8406099 | 6099 | USA | Modesto, CA | California | CA | 600 Gardner Road | Modesto | Stanislaus | . 4 8406071 | 6071 | USA | Rancho Cucamonga, CA | California | CA | 9535 Archibald Ave | Rancho Cucamonga | San Bernardino | . pep=pd.merge(pepsiLocations.astype(str), cena, on=[&#39;fips&#39;]) . cena . fips state pop . 0 1001 | Alabama | 55869 | . 1 1003 | Alabama | 223234 | . 2 1005 | Alabama | 24686 | . 3 1007 | Alabama | 22394 | . 4 1009 | Alabama | 57826 | . ... ... | ... | ... | . 3137 56037 | Wyoming | 42343 | . 3138 56039 | Wyoming | 23464 | . 3139 56041 | Wyoming | 20226 | . 3140 56043 | Wyoming | 7805 | . 3141 56045 | Wyoming | 6927 | . 3142 rows × 3 columns . pep.shape . (7, 10) . pep.columns . Index([&#39;uid&#39;, &#39;fips&#39;, &#39;country&#39;, &#39;facility&#39;, &#39;state&#39;, &#39;st&#39;, &#39;address&#39;, &#39;city&#39;, &#39;county&#39;, &#39;pop&#39;], dtype=&#39;object&#39;) . pep . uid fips country facility state_x st address city county state_y pop . 0 8405031 | 5031 | USA | Jonesboro, AR | Arkansas | AR | 2810 Quality Way | Jonesboro | Craighead | Arkansas | 23457 | . 1 8404021 | 4021 | USA | Casa Grande, AZ (Frito Lay) | Azizona | AZ | 1450 W Maricopa Hwy | Casa Grande | Pinal | Arizona | 110924 | . 2 8406029 | 6029 | USA | Bakersfield, CA (Frito Lay) | California | CA | 28801 Highway 58 | Bakersfield | Kern | California | 181215 | . 3 8406099 | 6099 | USA | Modesto, CA | California | CA | 600 Gardner Road | Modesto | Stanislaus | California | 447643 | . 4 8406071 | 6071 | USA | Rancho Cucamonga, CA | California | CA | 9535 Archibald Ave | Rancho Cucamonga | San Bernardino | California | 1552058 | . 5 8408031 | 8031 | USA | Denver, CO (Frito Lay) | Colorado | CO | 11645 East 37th Avenue | Denver | Denver | Colorado | 6061 | . 6 8409015 | 9015 | USA | Dayville, CT | nan | CT | 1886 Upper Maple St | Dayville | Windham | Connecticut | 854757 | . 7 84012095 | 12095 | USA | Orlando, FL (Frito Lay) | Florida | FL | 2800 Silver Star Road | Orlando | Orange | Florida | 88625 | . 8 84013153 | 13153 | USA | Kathleen, GA | Georgia | GA | 1200 Georgia Hwy 247 S | Kathleen | Houston | Georgia | 26205 | . 9 84013153 | 13153 | USA | Cedar Rapids, IA (Pepsi Quaker Foods) | nan | IA | 418 2nd St NE | Cedar Rapids | Linn | Georgia | 26205 | . 10 84013153 | 13153 | USA | Bridgeview, IL | Illinois | IL | 7700 W 71st Street | Bridgeview | Cook | Georgia | 26205 | . 11 84013153 | 13153 | USA | Danville, IL | Illinois | IL | 1703 E Voorhees Street | Danville | Vermilion | Georgia | 26205 | . 12 84013153 | 13153 | USA | Frankfort, IN (FL S County Rd) | nan | IN | 323 S County Road 300 West | Frankfort | Clinton | Georgia | 26205 | . 13 84013153 | 13153 | USA | Frankfort, IN (FL W County Rd) | nan | IN | 2611 W County Road O NS | Frankfort | Clinton | Georgia | 26205 | . 14 84013153 | 13153 | USA | Topeka, KS | Kansas | KS | 4236 Kirklawn Avenue | Topeka | Shawnee | Georgia | 26205 | . 15 84013153 | 13153 | USA | Randolph, MA | nan | MA | 663 North St | Randolph | Norfolk | Georgia | 26205 | . 16 84013153 | 13153 | USA | Aberdeen, MD | nan | MD | 800 Hickory Road | Aberdeen | Harford | Georgia | 26205 | . 17 84013153 | 13153 | USA | Columbia, MO | nan | MO | 4501 Paris Rd | Columbia | Boone | Georgia | 26205 | . 18 84013153 | 13153 | USA | Charlotte, NC (Frito Lay) | nan | NC | 2911 Nevada Boulevard | Charlotte | Mecklenburg | Georgia | 26205 | . 19 84013153 | 13153 | USA | Binghampton, NY | nan | NY | Broome Industrial Park 10 Spud Ln | Binghampton | Broome | Georgia | 26205 | . 20 84013153 | 13153 | USA | Canton, OH | Ohio | OH | 4030 16th Street SW | Canton | Stark | Georgia | 26205 | . 21 84013153 | 13153 | USA | Wooster, OH | Ohio | OH | 1626 Old Mansfield Road | Wooster | Wayne | Georgia | 26205 | . 22 84013153 | 13153 | USA | Williamsport, PA (Frito Lay) | Pennsylvania | PA | 220 North Reach Road | Williamsport | Lycoming | Georgia | 26205 | . 23 84013153 | 13153 | USA | York, PA | Pennsylvania | PA | 3553 Gillespie Dr | York | York | Georgia | 26205 | . 24 84013153 | 13153 | USA | Fayetteville, TN | Tennessee | TN | 101 Industrial Blvd | Fayetteville | Lincoln | Georgia | 26205 | . 25 84013153 | 13153 | USA | Pulaski, TN | Tennessee | TN | 298 Industrial Blvd | Pulaski | Giles | Georgia | 26205 | . 26 84013153 | 13153 | USA | Arlington, TX (Frito-Lay) | Texas | TX | 948 Avenue H East | Arlington | Tarrant | Georgia | 26205 | . 27 84013153 | 13153 | USA | Irving, TX | Texas | TX | 701 N Wildwood | Irving | Dallas | Georgia | 26205 | . 28 84013153 | 13153 | USA | Rosenberg , TX | Texas | TX | 3310 Hwy 36 North | Rosenberg | Fort Bend | Georgia | 26205 | . 29 84013153 | 13153 | USA | San Antonio, TX (Frito Lay) | Texas | TX | 4855 Greatland Drive | San Antonio | Bexar | Georgia | 26205 | . 30 84013153 | 13153 | USA | Salt Lake City, UT (Frito Lay) | nan | UT | 6301 West 4700 South | Salt Lake City | Salt Lake | Georgia | 26205 | . 31 84013153 | 13153 | USA | Lynchburg, VA | nan | VA | 230 Jefferson Ridge Parkway | Lynchburg | Campbell | Georgia | 26205 | . 32 84013153 | 13153 | USA | Vancouver ,WA | nan | WA | 4808 NW Fruit Valley Rd | Vancouver | Clark | Georgia | 26205 | . 33 84013153 | 13153 | USA | Beloit, WI | nan | WI | 2810 Kennedy Drive | Beloit | Rock | Georgia | 26205 | .",
            "url": "https://richcastro82.github.io/Notebooks/matrix/2020/09/02/Pepsi-Matrix.html",
            "relUrl": "/matrix/2020/09/02/Pepsi-Matrix.html",
            "date": " • Sep 2, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "TAG MATRIX DATA SCRAPER",
            "content": "import pandas as pd import requests import datetime date=datetime.datetime.now().strftime(&quot;%Y-%m-%d&quot;) import dash import dash_core_components as dcc . CANADA STUFF . #SOURCE - https://github.com/eebrown/data2019nCoV df=pd.read_csv(&#39;https://raw.githubusercontent.com/eebrown/data2019nCoV/master/data-raw/covid19.csv&#39;) df=df.rename(columns={&#39;pruid&#39;:&#39;uid&#39;, &#39;prname&#39;:&#39;province&#39;}) col=[&#39;uid&#39;, &#39;province&#39;,&#39;date&#39;, &#39;numconf&#39;, &#39;numprob&#39;, &#39;numdeaths&#39;, &#39;numtotal&#39;, &#39;numtested&#39;, &#39;numrecover&#39;, &#39;percentrecover&#39;, &#39;ratetested&#39;, &#39;numtoday&#39;, &#39;percentoday&#39;, &#39;ratetotal&#39;, &#39;ratedeaths&#39;, &#39;numdeathstoday&#39;, &#39;percentdeath&#39;, &#39;numtestedtoday&#39;, &#39;numrecoveredtoday&#39;, &#39;percentactive&#39;, &#39;numactive&#39;, &#39;rateactive&#39;, &#39;numtotal_last14&#39;, &#39;ratetotal_last14&#39;, &#39;numdeaths_last14&#39;, &#39;ratedeaths_last14&#39;] df_ca=df[col] df_ca.set_index(&#39;date&#39;, inplace=True) df_ca.to_csv(&#39;../data/sources/canada/&#39;+date+&#39;-eeBrown.csv&#39;) . #SOURCE - https://www12.statcan.gc.ca/census-recensement/index-eng.cfm df=pd.read_csv(&#39;https://www12.statcan.gc.ca/census-recensement/2016/dp-pd/hlt-fst/pd-pl/Tables/CompFile.cfm?Lang=Eng&amp;T=301&amp;OFT=FULLCSV&#39;) df_cacen=df df_cacen.to_csv(&#39;../data/sources/canada/&#39;+date+&#39;-ca_census.csv&#39;) . #SOURCE - ISHABERRY #PROVINCE LEVEL CASE DATA df=pd.read_csv(&#39;https://raw.githubusercontent.com/ishaberry/Covid19Canada/master/timeseries_prov/cases_timeseries_prov.csv&#39;) df.rename(columns={&#39;date_report&#39;:&#39;date&#39;}, inplace=True) df.set_index(&#39;date&#39;) df_Isha=df df_Isha.to_csv(&#39;../data/sources/canada/&#39;+date+&#39;Isha_Prov_Cases.csv&#39;) . #SOURCE - ISHABERRY #HEALTH REGION LEVEL CASE DATA df=pd.read_csv(&#39;https://raw.githubusercontent.com/ishaberry/Covid19Canada/master/timeseries_hr/cases_timeseries_hr.csv&#39;) df.rename(columns={&#39;date_report&#39;:&#39;date&#39;}, inplace=True) df.set_index(&#39;date&#39;) df_Isha=df df_Isha.to_csv(&#39;../data/sources/canada/&#39;+date+&#39;Isha_HR_Cases.csv&#39;) . #SOURCE - ISHABERRY #PROVINCE LEVEL TEST DATA df=pd.read_csv(&#39;https://raw.githubusercontent.com/ishaberry/Covid19Canada/master/timeseries_prov/testing_timeseries_prov.csv&#39;) df.rename(columns={&#39;date_testing&#39;:&#39;date&#39;}, inplace=True) df.set_index(&#39;date&#39;) df_Isha=df df_Isha.to_csv(&#39;../data/sources/canada/&#39;+date+&#39;Isha_Province_Testing.csv&#39;) . World-o-Meter . #WORLD O METER DATA #NEW YORK COUNTY DATA import datetime date=datetime.datetime.now().strftime(&quot;%Y-%m-%d&quot;) web=requests.get(&#39;https://www.worldometers.info/coronavirus/usa/new-york&#39;) ny=pd.read_html(web.text) ny=ny[1] ny.columns=map(str.lower, ny.columns) ny.to_csv(&#39;../data/sources/worldometer/&#39;+date+&#39;-NY-County-Data.csv&#39;) #CALIFORNIA COUNTY DATA cad=requests.get(&#39;https://www.worldometers.info/coronavirus/usa/california&#39;) ca=pd.read_html(cad.text) ca=ca[1] ca.columns=map(str.lower, ca.columns) ca.to_csv(&#39;../data/sources/worldometer/&#39;+date+&#39;-CA-County-Data.csv&#39;) #NEW JERSEY COUNTY DATA njd=requests.get(&#39;https://www.worldometers.info/coronavirus/usa/new-jersey&#39;) nj=pd.read_html(njd.text) nj=nj[1] nj.columns=map(str.lower, nj.columns) nj.to_csv(&#39;../data/sources/worldometer/&#39;+date+&#39;-NJ-County-Data.csv&#39;) #OHIO COUNTY DATA ohd=requests.get(&#39;https://www.worldometers.info/coronavirus/usa/ohio/&#39;) oh=pd.read_html(ohd.text) oh=oh[1] oh.columns=map(str.lower, oh.columns) oh.to_csv(&#39;../data/sources/worldometer/&#39;+date+&#39;-OH-County-Data.csv&#39;) #SOUTH CAROLINA COUNTY DATA scd=requests.get(&#39;https://www.worldometers.info/coronavirus/usa/south-carolina/&#39;) sc=pd.read_html(scd.text) sc=sc[1] sc.columns=map(str.lower, sc.columns) sc.to_csv(&#39;../data/sources/worldometer/&#39;+date+&#39;-SC-County-Data.csv&#39;) #PA COUNTY DATA pad=requests.get(&#39;https://www.worldometers.info/coronavirus/usa/pennsylvania/&#39;) pa=pd.read_html(pad.text) pa=pa[1] pa.columns=map(str.lower, pa.columns) pa.to_csv(&#39;../data/sources/worldometer/&#39;+date+&#39;-PA-County-Data.csv&#39;) #WASHINGTON COUNTY DATA wad=requests.get(&#39;https://www.worldometers.info/coronavirus/usa/washington/&#39;) wa=pd.read_html(wad.text) wa=wa[1] wa.columns=map(str.lower, wa.columns) wa.to_csv(&#39;../data/sources/worldometer/&#39;+date+&#39;-WA-County-Data.csv&#39;) #US STATE LEVEL DATA we=requests.get(&#39;https://www.worldometers.info/coronavirus/country/us/&#39;) us=pd.read_html(we.text) us=us[1] us.to_csv(&#39;../data/sources/worldometer/&#39;+date+&#39;-US-State-Data.csv&#39;) . rt live . rtlive=pd.read_csv(&#39;https://d14wlfuexuxgcm.cloudfront.net/covid/rt.csv&#39;) rtlive.to_csv(&#39;../_data/data_sources/rtlive/rtlive&#39;+date+&#39;.csv&#39;) . Mobility Reports . Google Mobility Reports | Apple Mobility Reports | . #GOOGLE AND APPLE MOBILITY DATA BY COUNTY #apple=pd.read_csv(&#39;https://covid19-static.cdn-apple.com/covid19-mobility-data/2014HotfixDev8/v3/en-us/applemobilitytrends-2020-08-08.csv&#39;) #apple.to_csv(&#39;../_data/Data_Sources/Mobility_Reports/apple.csv&#39;) google=pd.read_csv(&#39;https://www.gstatic.com/covid19/mobility/Global_Mobility_Report.csv&#39;) google.to_csv(&#39;../_data/Data_Sources/google/google.csv&#39;) . WORLD-O-METER DATASETS . NEW YORK CALIFORNIA NEW JERSEY PA SOUTH CAROLINA OHIO WASHINGTON STATE &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; healthDepartment=requests.get(&#39;https://data.ct.gov/Health-and-Human-Services/COVID-19-Tests-Cases-and-Deaths-By-Town-/28fr-iqnx/data&#39;) hd=pd.read_html(healthDepartment.text) . COUNTY HEALTH DEPARTMANT DATASETS . #HEALTH DEPARTMENTS DATA flData=pd.read_csv(&#39;https://opendata.arcgis.com/datasets/222c9d85e93540dba523939cfb718d76_0.csv?outSR=%7B%22latestWkid%22%3A4326%2C%22wkid%22%3A4326%7D&#39;) flData.to_csv(&#39;../_data/Data_Sources/Fl-Data.csv&#39;) miData=pd.read_excel(&#39;https://www.michigan.gov/documents/coronavirus/Covid-19_Tests_by_County_2020-08-08_698830_7.xlsx&#39;) miData.to_csv(&#39;../_data/Data_Sources/Health-Department-Data/MI-Tests-County.csv&#39;) miData2=pd.read_excel(&#39;https://www.michigan.gov/documents/coronavirus/Cases_by_County_and_Date_2020-08-08_698828_7.xlsx&#39;) miData2.to_csv(&#39;../_data/Data_Sources/Health-Department-Data/MI-Cases-County.csv&#39;) miData3=pd.read_excel(&#39;https://www.michigan.gov/documents/coronavirus/Cases_and_Deaths_by_County_2020-08-08_698827_7.xlsx&#39;) miData3.to_csv(&#39;../_data/Data_Sources/Health-Department-Data/MI-Deaths-Cases-County.csv&#39;) miData4=pd.read_csv(&#39;https://raw.githubusercontent.com/jeffcore/covid-19-usa-by-state/master/COVID-19-Cases-USA-By-County.csv&#39;) miData4.to_csv(&#39;../_data/Data_Sources/Health-Department-Data/COVID-19-Cases-USA-By-County.csv&#39;) miData5=pd.read_csv(&#39;https://raw.githubusercontent.com/jeffcore/covid-19-usa-by-state/master/COVID-19-Deaths-USA-By-County.csv&#39;) miData5.to_csv(&#39;../_data/Data_Sources/Health-Department-Data/COVID-19-Deaths-USA-By-County.csv&#39;) miData6=pd.read_csv(&#39;https://raw.githubusercontent.com/jeffcore/covid-19-usa-by-state/master/COVID-19-Cases-USA-By-State.csv&#39;) miData6.to_csv(&#39;../_data/Data_Sources/Health-Department-Data/COVID-19-Cases-USA-By-State.csv&#39;) miData7=pd.read_csv(&#39;https://raw.githubusercontent.com/jeffcore/covid-19-usa-by-state/master/COVID-19-Deaths-USA-By-State.csv&#39;) miData7.to_csv(&#39;../_data/Data_Sources/Health-Department-Data/COVID-19-Deaths-USA-By-State.csv&#39;) . #ANOTHER MODULE from bs4 import BeautifulSoup url=requests.get(&#39;https://covidactnow.org/us/fl/county/taylor_county?s=846164&#39;) soup = BeautifulSoup(requests.get(url).text) soup.findAll(&quot;table&quot;)[0].findAll(&quot;tr&quot;)[0] . COVID TRACKER DATA . #COVID TRACKER DATA da1=pd.read_html(&#39;https://covidtracking.com/data/state/alabama&#39;) da1[1].to_csv(&#39;../_data/Data_Sources/CovidTracker/Alabama.csv&#39;) da2=pd.read_html(&#39;https://covidtracking.com/data/state/alaska&#39;) da2[1].to_csv(&#39;../_data/Data_Sources/CovidTracker/Alaska.csv&#39;) da3=pd.read_html(&#39;https://covidtracking.com/data/state/arizona&#39;) da3[1].to_csv(&#39;../_data/Data_Sources/CovidTracker/Arizona.csv&#39;) AR_COVIDTRACKER=pd.read_html(&#39;https://covidtracking.com/data/state/arkansas&#39;) AR_COVIDTRACKER[1].to_csv(&#39;../_data/data_sources/covidtracker/&#39;+date+&#39;-ARKANSAS.csv&#39;) CA_COVIDTRACKER=pd.read_html(&#39;https://covidtracking.com/data/state/california&#39;) CA_COVIDTRACKER[1].to_csv(&#39;../_data/data_sources/covidtracker/&#39;+date+&#39;-CALIFORNIA.csv&#39;) GA_COVIDTRACKER=pd.read_html(&#39;https://covidtracking.com/data/state/GEORGIA&#39;) GA_COVIDTRACKER[1].to_csv(&#39;../_data/data_sources/covidtracker/&#39;+date+&#39;-GEORGIA.csv&#39;) KS_COVIDTRACKER=pd.read_html(&#39;https://covidtracking.com/data/state/KANSAS&#39;) KS_COVIDTRACKER[1].to_csv(&#39;../_data/data_sources/covidtracker/&#39;+date+&#39;-KANSAS.csv&#39;) FL_COVIDTRACKER=pd.read_html(&#39;https://covidtracking.com/data/state/FLORIDA&#39;) FL_COVIDTRACKER[1].to_csv(&#39;../_data/data_sources/covidtracker/&#39;+date+&#39;-FLORIDA.csv&#39;) IL_COVIDTRACKER=pd.read_html(&#39;https://covidtracking.com/data/state/ILLINOIS&#39;) IL_COVIDTRACKER[1].to_csv(&#39;../_data/data_sources/covidtracker/&#39;+date+&#39;-ILLINOIS.csv&#39;) OH_COVIDTRACKER=pd.read_html(&#39;https://covidtracking.com/data/state/OHIO&#39;) OH_COVIDTRACKER[1].to_csv(&#39;../_data/data_sources/covidtracker/&#39;+date+&#39;-OHIO.csv&#39;) TN_COVIDTRACKER=pd.read_html(&#39;https://covidtracking.com/data/state/TENNESSEE&#39;) TN_COVIDTRACKER[1].to_csv(&#39;../_data/data_sources/covidtracker/&#39;+date+&#39;-TENNESSEE.csv&#39;) NE_COVIDTRACKER=pd.read_html(&#39;https://covidtracking.com/data/state/NEBRASKA&#39;) NE_COVIDTRACKER[1].to_csv(&#39;../_data/data_sources/covidtracker/&#39;+date+&#39;-NEBRASKA.csv&#39;) PA_COVIDTRACKER=pd.read_html(&#39;https://covidtracking.com/data/state/PENNSYLVANIA&#39;) PA_COVIDTRACKER[1].to_csv(&#39;../_data/data_sources/covidtracker/&#39;+date+&#39;-PENNSYLVANIA.csv&#39;) NC_COVIDTRACKER=pd.read_html(&#39;https://covidtracking.com/data/state/NORTH-CAROLINA&#39;) NC_COVIDTRACKER[1].to_csv(&#39;../_data/data_sources/covidtracker/&#39;+date+&#39;-NORTHCAROLINA.csv&#39;) KY_COVIDTRACKER=pd.read_html(&#39;https://covidtracking.com/data/state/KENTUCKY&#39;) KY_COVIDTRACKER[1].to_csv(&#39;../_data/data_sources/covidtracker/&#39;+date+&#39;-KENTUCKY.csv&#39;) CO_COVIDTRACKER=pd.read_html(&#39;https://covidtracking.com/data/state/COLORADO&#39;) CO_COVIDTRACKER[1].to_csv(&#39;../_data/data_sources/covidtracker/&#39;+date+&#39;-COLORADO.csv&#39;) KS_COVIDTRACKER=pd.read_html(&#39;https://covidtracking.com/data/state/KENTUCKY&#39;) KS_COVIDTRACKER[1].to_csv(&#39;../_data/data_sources/covidtracker/&#39;+date+&#39;-KENTUCKY.csv&#39;) NJ_COVIDTRACKER=pd.read_html(&#39;https://covidtracking.com/data/state/NEW-JERSEY&#39;) NJ_COVIDTRACKER[1].to_csv(&#39;../_data/data_sources/covidtracker/&#39;+date+&#39;-NEWJERSEY.csv&#39;) MN_COVIDTRACKER=pd.read_html(&#39;https://covidtracking.com/data/state/MINNESOTA&#39;) MN_COVIDTRACKER[1].to_csv(&#39;../_data/data_sources/covidtracker/&#39;+date+&#39;-MINNESOTA.csv&#39;) MI_COVIDTRACKER=pd.read_html(&#39;https://covidtracking.com/data/state/MICHIGAN&#39;) MI_COVIDTRACKER[1].to_csv(&#39;../_data/data_sources/covidtracker/&#39;+date+&#39;-MICHIGAN.csv&#39;) . NEW YORK TIMES DATA . #NEW YORK TIMES DATA MASK_NYT=pd.read_csv(&#39;https://raw.githubusercontent.com/nytimes/covid-19-data/master/mask-use/mask-use-by-county.csv&#39;) MASK_NYT.to_csv(&#39;../_data/data_sources/NYT/MASKUSAGE-&#39;+date+&#39;.csv&#39;) CASESDEATHSC_NYT=pd.read_csv(&#39;https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv&#39;) CASESDEATHSC_NYT.to_csv(&#39;../_data/data_sources/NYT/CASES-DEATHS-COUNTY-&#39;+date+&#39;.csv&#39;) CASESDEATHS_NYT=pd.read_csv(&#39;https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv&#39;) CASESDEATHS_NYT.to_csv(&#39;../_data/data_sources/NYT/CASES-DEATHS-STATE-&#39;+date+&#39;.csv&#39;) CASESDEATHSCD_NYT=pd.read_csv(&#39;https://raw.githubusercontent.com/nytimes/covid-19-data/master/live/us-counties.csv&#39;) CASESDEATHSCD_NYT.to_csv(&#39;../_data/data_sources/NYT/CASES-DEATHS-COUNTY-DAILY-&#39;+date+&#39;.csv&#39;) CASESDEATHSD_NYT=pd.read_csv(&#39;https://raw.githubusercontent.com/nytimes/covid-19-data/master/live/us-states.csv&#39;) CASESDEATHSD_NYT.to_csv(&#39;../_data/data_sources/NYT/CASES-DEATHS-STATE-DAILY-&#39;+date+&#39;.csv&#39;) EXDEATHS_NYT=pd.read_csv(&#39;https://raw.githubusercontent.com/nytimes/covid-19-data/master/excess-deaths/deaths.csv&#39;) EXDEATHS_NYT.to_csv(&#39;../_data/data_sources/NYT/EXCESS-DEATHS-CITY-&#39;+date+&#39;.csv&#39;) . linlab . LINLAB=pd.read_csv(&#39;https://raw.githubusercontent.com/lin-lab/COVID19-Viz/master/clean_data/rt_table_export.csv&#39;) LINLAB.to_csv(&#39;../_data/data_sources/LINLAB/RTCOUNTYLEVEL-&#39;+date+&#39;.csv&#39;) . wew=requests.get(&#39;https://www.geonames.org/statistics/&#39;) us=pd.read_html(wew.text) us[1].to_csv(&#39;../_data/data_sources/worldCountryPopulations.csv&#39;) . &lt;/div&gt; | | | | | | | .",
            "url": "https://richcastro82.github.io/Notebooks/matrix/2020/09/02/Matrix-Data-Scrapper.html",
            "relUrl": "/matrix/2020/09/02/Matrix-Data-Scrapper.html",
            "date": " • Sep 2, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "KERRY MATRIX",
            "content": "#collapse #IMPORTING LIBRARIES AND DATA FILES import pandas as pd mat=pd.read_csv(&#39;../us_m.csv&#39;) kerry=pd.read_csv(&#39;../kerry.csv&#39;) rt = pd.read_csv(&#39;https://d14wlfuexuxgcm.cloudfront.net/covid/rt.csv&#39;) da = pd.read_csv(&#39;https://covidtracking.com/api/v1/states/daily.csv&#39;) . . #collapse #FORMATING DATA FROM LAST WEEKS MATRIX TO MOVE WEEKLY DATA OVER mat.columns = map(str.lower, mat.columns) col=[&#39;state&#39;,&#39;social index current&#39;,&#39;rt current&#39;,&#39;test increase current&#39;,&#39;tpr current&#39;, &#39;weekly deaths current&#39;,&#39;total deaths current&#39;,&#39;total tests current&#39;] newCol=mat[col] newerCol=newCol.rename(columns={&#39;social index current&#39;:&#39;social index past&#39; ,&#39;rt current&#39;:&#39;rt past&#39; ,&#39;test increase current&#39;:&#39;test increase past&#39;, &#39;tpr current&#39;:&#39;tpr past&#39;, &#39;weekly deaths current&#39;:&#39;weekly deaths past&#39;, &#39;total deaths current&#39;:&#39;total deaths past&#39;, &#39;total tests current&#39;:&#39;total tests past&#39;}) kerry.columns=map(str.lower, kerry.columns) . . #collapse #CLEANING THE RTLIVE DATA today=&#39;2020-08-03&#39; rtCleaned = rt[rt[&#39;date&#39;]==today] rtColumns = [&#39;date&#39;, &#39;region&#39;, &#39;mean&#39;] rtCleaned = rtCleaned[rtColumns] rtCleaned = rtCleaned.rename(columns = {&#39;region&#39;:&#39;state&#39;}) rtCleaned = rtCleaned.sort_values(&#39;state&#39;, ascending=True) . . #collapse #CLEANING THE DAILY COVID DATA dateRange=&#39;20200803&#39; dailyColumns = [&#39;date&#39;, &#39;state&#39;, &#39;death&#39;, &#39;positiveIncrease&#39;, &#39;totalTestResultsIncrease&#39;, &#39;deathIncrease&#39;] dailyData = da[dailyColumns] dailyData = dailyData.sort_values(&#39;state&#39;, ascending=True) dailyCleaned = dailyData[dailyData[&#39;date&#39;].astype(str)==dateRange] . . #collapse #MERGING THE DATASETS TOGETHER mergef=pd.merge(kerry, rtCleaned, on=&#39;state&#39;) merget=pd.merge(mergef, dailyCleaned, on=&#39;state&#39;) merger=pd.merge(merget, newerCol, on=&#39;state&#39;) . . #SHOW THE LOCATIONS FOR CLIENT kerry . state population . 0 AL | 4903185 | . 1 AR | 3017804 | . 2 CA | 39512223 | . 3 FL | 21477737 | . 4 GA | 10617423 | . 5 IA | 3155070 | . 6 IL | 12671821 | . 7 IN | 6732219 | . 8 KS | 2913314 | . 9 MD | 6045680 | . 10 ME | 1344212 | . 11 MN | 5639632 | . 12 MO | 6137428 | . 13 MS | 2976149 | . 14 NJ | 8882190 | . 15 NY | 19453561 | . 16 OH | 11689100 | . 17 TN | 6829174 | . 18 TX | 28995881 | . 19 VA | 8535519 | . 20 WA | 7614893 | . 21 WI | 5822434 | . #SHOW CLIP OF THE RT DATA rtCleaned.head(3) . date state mean . 8000 2020-08-03 | AK | 1.045968 | . 3675 2020-08-03 | AL | 1.037615 | . 4948 2020-08-03 | AR | 1.032516 | . #SHOW CLIP OF THE DAILY DATA dailyCleaned.head(3) . date state death positiveIncrease totalTestResultsIncrease deathIncrease . 112 20200803 | AK | 25.0 | 80 | 2717 | 1 | . 113 20200803 | AL | 1633.0 | 1217 | 7981 | 6 | . 114 20200803 | AR | 475.0 | 1424 | 12819 | 17 | . #SHOW CLIP OF THE PAST DATA newerCol.head(3) . state social index past rt past test increase past tpr past weekly deaths past total deaths past total tests past . 0 AL | 22 | 1.111944 | 11546 | 21% | 142 | 1633 | 56092 | . 1 AR | 76 | 1.037065 | 5150 | 12% | 67 | 475 | 42509 | . 2 CA | 22 | 0.970088 | 54351 | 6% | 943 | 9388 | 888118 | . #SHOW THE MERGED DATA merger . state population date_x mean date_y death positiveIncrease totalTestResultsIncrease deathIncrease social index past rt past test increase past tpr past weekly deaths past total deaths past total tests past . 0 AL | 4903185 | 2020-08-03 | 1.037615 | 20200803 | 1633.0 | 1217 | 7981 | 6 | 22 | 1.111944 | 11546 | 21% | 142 | 1633 | 56092 | . 1 AR | 3017804 | 2020-08-03 | 1.032516 | 20200803 | 475.0 | 1424 | 12819 | 17 | 76 | 1.037065 | 5150 | 12% | 67 | 475 | 42509 | . 2 CA | 39512223 | 2020-08-03 | 0.887432 | 20200803 | 9388.0 | 5739 | 148721 | 32 | 22 | 0.970088 | 54351 | 6% | 943 | 9388 | 888118 | . 3 FL | 21477737 | 2020-08-03 | 0.965805 | 20200803 | 7279.0 | 4752 | 31801 | 73 | 85 | 0.986019 | 59137 | 18% | 1230 | 7279 | 321301 | . 4 GA | 10617423 | 2020-08-03 | 0.953591 | 20200803 | 3842.0 | 2258 | 21761 | 2 | 22 | 0.953783 | 24592 | 13% | 333 | 3842 | 193438 | . 5 IA | 3155070 | 2020-08-03 | 0.986369 | 20200803 | 882.0 | 349 | 2357 | 6 | 16 | 1.010162 | 3287 | 10% | 49 | 882 | 31630 | . 6 IL | 12671821 | 2020-08-03 | 1.079520 | 20200803 | 7723.0 | 1298 | 28475 | 9 | 44 | 1.092876 | 10625 | 4% | 115 | 7723 | 264702 | . 7 IN | 6732219 | 2020-08-03 | 1.005326 | 20200803 | 2980.0 | 576 | 6439 | 5 | 54 | 1.001587 | 5526 | 8% | 74 | 2980 | 67691 | . 8 KS | 2913314 | 2020-08-03 | 1.062584 | 20200803 | 365.0 | 1064 | 9332 | 7 | 46 | 1.071201 | 2704 | 12% | 30 | 365 | 22903 | . 9 MD | 6045680 | 2020-08-03 | 1.031896 | 20200803 | 3523.0 | 870 | 15851 | 8 | 45 | 1.047616 | 6268 | 6% | 76 | 3523 | 105119 | . 10 ME | 1344212 | 2020-08-03 | 0.935590 | 20200803 | 124.0 | 12 | 2071 | 1 | 45 | 0.975832 | 138 | 1% | 5 | 124 | 16704 | . 11 MN | 5639632 | 2020-08-03 | 1.103790 | 20200803 | 1656.0 | 613 | 13663 | 2 | 45 | 1.074376 | 4757 | -5% | 40 | 1656 | -98722 | . 12 MO | 6137428 | 2020-08-03 | 1.166522 | 20200803 | 1255.0 | 1047 | 10481 | 2 | 1 | 1.220294 | 9837 | 14% | 54 | 1255 | 71044 | . 13 MS | 2976149 | 2020-08-03 | 1.071332 | 20200803 | 1711.0 | 572 | 572 | 8 | 13 | 1.061724 | 8168 | 23% | 210 | 1711 | 35120 | . 14 NJ | 8882190 | 2020-08-03 | 0.975566 | 20200803 | 15846.0 | 264 | 18702 | 10 | 15 | 0.965851 | 2802 | 2% | 42 | 15846 | 180739 | . 15 NY | 19453561 | 2020-08-03 | 0.963728 | 20200803 | 25172.0 | 545 | 51839 | 2 | 52 | 0.941746 | 4499 | 1% | 55 | 25172 | 455625 | . 16 OH | 11689100 | 2020-08-03 | 0.941189 | 20200803 | 3539.0 | 932 | 17997 | 10 | 64 | 0.918456 | 8786 | 5% | 195 | 3539 | 191445 | . 17 TN | 6829174 | 2020-08-03 | 0.986842 | 20200803 | 1092.0 | 1009 | 12235 | 19 | 15 | 0.980140 | 14147 | 9% | 114 | 1092 | 163081 | . 18 TX | 28995881 | 2020-08-03 | 0.957834 | 20200803 | 7016.0 | 11529 | 86807 | 179 | 35 | 0.933380 | 56091 | 14% | 1303 | 7016 | 405704 | . 19 VA | 8535519 | 2020-08-03 | 1.096200 | 20200803 | 2218.0 | 1324 | 15082 | 0 | 85 | 1.023291 | 7034 | 6% | 136 | 2218 | 115897 | . 20 WA | 7614893 | 2020-08-03 | 1.091667 | 20200803 | 1596.0 | 632 | 6752 | 4 | 25 | 1.012360 | 5538 | 6% | 95 | 57 | 88933 | . 21 WI | 5822434 | 2020-08-03 | 0.918711 | 20200803 | 956.0 | 411 | 7180 | 1 | 26 | 0.985503 | 6120 | 7% | 56 | 1596 | 93650 | .",
            "url": "https://richcastro82.github.io/Notebooks/matrix/2020/09/02/Kerry_Matrix_2.0.html",
            "relUrl": "/matrix/2020/09/02/Kerry_Matrix_2.0.html",
            "date": " • Sep 2, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "KELLOGGS MATRIX",
            "content": "#collapse-hide #IMPORT LIBRARIES FROM PYTHON import pandas as pd pd.options.display.max_rows = 2800 . . #collapse-hide #IMPORT DATA SETS FROM TRUSTED SOURCES #US CENSUS DATA FROM - censusData = pd.read_csv(&#39;../_data/cen.csv&#39;) censusData.columns=map(str.lower, censusData.columns) #COUNTY MASK USAGE FROM - maskData = pd.read_csv(&#39;../_data/maskbycounty.csv&#39;) maskData.columns=map(str.lower, maskData.columns) #CLIENT LOCATION DATA locations=pd.read_csv(&#39;../_data/kellogg_locations.csv&#39;) locations loc=[&#39;state&#39;, &#39;county&#39;] showLocs=locations[loc] showLocs.set_index(&#39;state&#39;, inplace=True) print(&#39;These are the US Locations for: Kelloggs&#39;) showLocs . . #collapse-hide #IMPORT LIBRARIES import numpy as np from matplotlib import pyplot as plt from mpl_toolkits.basemap import Basemap cities = pd.read_csv(&#39;../_data/client_locations/kelloggs.csv&#39;) lat = cities[&#39;lat&#39;].values lon = cities[&#39;long_&#39;].values population = cities[&#39;active&#39;].values area = cities[&#39;tee&#39;].values #collapse-hide fig = plt.figure(figsize=(18, 10)) m = Basemap(llcrnrlon=-119,llcrnrlat=22,urcrnrlon=-64,urcrnrlat=49, projection=&#39;lcc&#39;, resolution=&#39;l&#39;, lat_1=33,lat_2=45,lon_0=-95) m.shadedrelief() m.drawcoastlines(color=&#39;gray&#39;) m.drawcountries(color=&#39;gray&#39;) m.drawstates(color=&#39;gray&#39;) m.drawcounties(color=&#39;gray&#39;) m.scatter(lon, lat, latlon=True, c=np.log10(population), s=area, cmap=&#39;Reds&#39;, alpha=1) plt.title(&quot;Kelloggs Locations&quot;) plt.colorbar(label=r&#39;Covid Cases(Active)&#39;) plt.clim(3, 7) . . #collapse-hide #RTLIVE DATA rt=pd.read_csv(&#39;../_data/rt.csv&#39;) #TN DATA IMPORT tn=pd.read_csv(&#39;../_data/tn.csv&#39;) tn.columns=map(str.lower, tn.columns) #OH DATA IMPORT oh=pd.read_csv(&#39;../_data/ohio.csv&#39;) oh.columns=map(str.lower, oh.columns) #FL DATA IMPORT fl=pd.read_csv(&#39;../_data/fl.csv&#39;) fl.columns=map(str.lower, fl.columns) #RT DATA CLEANING rt=rt.rename(columns={&#39;region&#39;:&#39;st&#39;}) rtC=[&#39;date&#39;, &#39;st&#39;, &#39;mean&#39;] rta=rt[rtC] #CLIENT AND RT DATA MERGE LocationRT=pd.merge(locations, rta, on=&#39;st&#39;) Location=LocationRT[LocationRT[&#39;date&#39;]==&#39;8/2/2020&#39;] #CENSUS DATA CLEANING cenC=[&#39;fips&#39;,&#39;popestimate2019&#39;] cen=censusData[cenC] #CLIENT AND CENSUS DATA MERGE locationCen=pd.merge(Location.astype(str), cen, on=&#39;fips&#39;) locationMask=pd.merge(locationCen, maskData.astype(str), on=&#39;fips&#39;) matrixReport=locationMask locations . . #collapse-hide tn=tn.rename(columns={&#39;state&#39;:&#39;st&#39;, &#39;test_pos&#39;:&#39;testP&#39;, &#39;test_neg&#39;:&#39;testN&#39;, &#39;test_tot&#39;:&#39;testT&#39;, &#39;test_new&#39;:&#39;testNew&#39;, &#39;cases_confirmed&#39;:&#39;cases&#39;, &#39;new_cases_confirmed&#39;:&#39;casesNewCf&#39;, &#39;cases_probable&#39;:&#39;casesP&#39;, &#39;cases_new_probable&#39;:&#39;casesNP&#39;, &#39;cases_tot&#39;:&#39;caseT&#39;, &#39;cases_new&#39;:&#39;caseNew&#39;, &#39;hospitalized_tot&#39;:&#39;hospT&#39;, &#39;hospitalized_new&#39;:&#39;hospN&#39;, &#39;recov_tot&#39;:&#39;recT&#39;, &#39;recov_new&#39;:&#39;recN&#39;, &#39;deaths_tot&#39;:&#39;deathsT&#39;, &#39;deaths_new&#39;:&#39;deathsNew&#39;, &#39;active_tot&#39;:&#39;actT&#39;, &#39;active_new&#39;:&#39;actNew&#39;}) tnCol=[&#39;date&#39;, &#39;st&#39;, &#39;county&#39;, &#39;testP&#39;, &#39;testN&#39;, &#39;testT&#39;,&#39;testNew&#39;, &#39;cases&#39;, &#39;casesNewCf&#39;,&#39;casesP&#39;, &#39;casesNP&#39;, &#39;caseT&#39;, &#39;caseNew&#39;, &#39;hospT&#39;,&#39;hospN&#39;, &#39;recT&#39;, &#39;recN&#39;, &#39;deathsT&#39;, &#39;deathsNew&#39;, &#39;actT&#39;, &#39;actNew&#39;] tnc=tn[tnCol] tnc . . #collapse-hide fl=fl.rename(columns={&#39;cases_c&#39;:&#39;caseT&#39;, &#39;test_t&#39;:&#39;testT&#39;, &#39;test_n&#39;:&#39;testN&#39;, &#39;test_p&#39;:&#39;testP&#39;, &#39;deaths_tot&#39;:&#39;deathsT&#39;}) flCol=[&#39;county&#39;, &#39;state&#39;, &#39;caseT&#39;, &#39;testT&#39;, &#39;testN&#39;, &#39;testP&#39;, &#39;deathsT&#39;] flc=fl[flCol] . . #collapse-hide ohCol=[&#39;case count&#39;, &#39;death count&#39;, &#39;hospitalized count&#39;, &#39;fips&#39;] ohC=oh[ohCol] ohC=ohC.rename(columns={&#39;case count&#39;:&#39;caseT&#39;, &#39;death count&#39;:&#39;deathT&#39;, &#39;hospitalized count&#39;:&#39;hospT&#39;}) . . #collapse-hide matrixMix=pd.merge(matrixReport, ohC.astype(str), on=&#39;fips&#39;, how=&#39;left&#39;) flc=flc.rename(columns={&#39;state&#39;:&#39;st&#39;}) matrixM=pd.merge(matrixMix, flc, on=[&#39;county&#39;, &#39;st&#39;], how=&#39;left&#39;) matrixM.head(1) . . #collapse-hide tnc.columns . . #collapse-hide mat=pd.merge(matrixM.astype(str)[pd.notnull], tnc.astype(str)[pd.notnull], on=[&#39;st&#39;, &#39;county&#39;, &#39;deathsT&#39;, &#39;testT&#39;, &#39;testN&#39;, &#39;hospT&#39;], how=&#39;left&#39;) pd.options.display.max_rows = 2800 pd.options.display.max_columns = 2800 mat . . #collapse-hide #RT DATA FROM - D=pd.read_csv(&#39;../_data/rttestcounty.csv&#39;) countyData = pd.read_csv(&#39;../_data/isee.csv&#39;) rtData = pd.read_csv(&#39;https://d14wlfuexuxgcm.cloudfront.net/covid/rt.csv&#39;) #CLEAN UP DATA AND STANDARDIZE THE COLUMNS ACol=[ &#39;uid&#39;, &#39;date&#39;, &#39;resolution&#39;, &#39;date_lag&#39;, &#39;Rt_plot&#39;, &#39;Rt_upr&#39;, &#39;Rt_lwr&#39;, &#39;Rt_loess_fit&#39;, &#39;Rt_loess_lwr&#39;, &#39;Rt_loess_upr&#39;, &#39;positiveIncrease&#39;, &#39;positive&#39;, &#39;positive_7day&#39;, &#39;positive_percapita&#39;, &#39;positiveIncr_percapita&#39;, &#39;deathIncrease&#39;, &#39;death&#39;, &#39;death_percapita&#39;, &#39;deathIncr_percapita&#39;] As=countyData[ACol] pCol=[&#39;fips&#39;, &#39;POPESTIMATE2019&#39;] censusDataCleaned=censusData[pCol] #KELLOGGS LOCATIONS clientLocations=pd.read_csv(&#39;../_data/kellogg_locations.csv&#39;) fCol=[&#39;uid&#39;, &#39;fips&#39;, &#39;state&#39;, &#39;county&#39;] clientDataCleaned=clientLocations[fCol] clientDataCleaned mergeClientCensus=pd.merge(censusDataCleaned, clientDataCleaned.astype(str), on =&quot;fips&quot;) mergeData=mergeClientCensus.sort_values(&#39;state&#39;) md=pd.merge(mergeData, D.astype(str), on=&#39;fips&#39;) mn=md.sort_values(&#39;state&#39;) UT=pd.merge(mergeData, As.astype(str), on=&#39;uid&#39;) today = &#39;08/01/2020&#39; UTT = UT[UT[&#39;date&#39;]==today] AwA=pd.merge(As.astype(str), mergeData, on=&#39;uid&#39;, ) AwCol=[ &#39;state&#39;, &#39;county&#39;, &#39;date&#39;, &#39;resolution&#39;, &#39;Rt_plot&#39;, &#39;Rt_upr&#39;, &#39;Rt_lwr&#39;, &#39;Rt_loess_fit&#39;, &#39;Rt_loess_lwr&#39;, &#39;Rt_loess_upr&#39;, &#39;positiveIncrease&#39;, &#39;positive&#39;, &#39;positive_7day&#39;, &#39;positive_percapita&#39;, &#39;positiveIncr_percapita&#39;, &#39;deathIncrease&#39;, &#39;death&#39;, &#39;death_percapita&#39;, &#39;deathIncr_percapita&#39;, &#39;POPESTIMATE2019&#39;, &#39;fips&#39; ] AwCleaned = AwA[AwCol] ATT=pd.merge(AwCleaned, maskData.astype(str), on=&#39;fips&#39;) pd.options.display.max_rows = 2800 ATCol=[&#39;state&#39;, &#39;county&#39;, &#39;date&#39;, &#39;Rt_plot&#39;, &#39;positiveIncrease&#39;, &#39;positive&#39;, &#39;positive_7day&#39;, &#39;positive_percapita&#39;, &#39;positiveIncr_percapita&#39;, &#39;deathIncrease&#39;, &#39;death&#39;, &#39;death_percapita&#39;, &#39;deathIncr_percapita&#39;, &#39;POPESTIMATE2019&#39;, &#39;NEVER&#39;, &#39;RARELY&#39;, &#39;SOMETIMES&#39;, &#39;FREQUENTLY&#39;, &#39;ALWAYS&#39;] ATR=ATT[ATCol] ATY = ATR[ATR[&#39;date&#39;]==&#39;7/18/2020&#39;] . .",
            "url": "https://richcastro82.github.io/Notebooks/matrix/2020/09/02/Kelloggs_Matrix.html",
            "relUrl": "/matrix/2020/09/02/Kelloggs_Matrix.html",
            "date": " • Sep 2, 2020"
        }
        
    
  
    
  
    
        ,"post5": {
            "title": "This notebook will create the client filtered LinLab pull",
            "content": "This is for you Lily . you can delete this module whenever. . STEP 1: IMPORT LIBRARIES . import pandas as pd import datetime #GET THE CLIENT FILE READY date=datetime.datetime.now().strftime(&quot;%Y-%m-%d&quot;) . STEP 2: SELECT THE CLIENT . client_select=input(&#39;Select Client: &#39;) client_df=pd.read_csv(&#39;../data/clients/&#39;+client_select+&#39;/&#39;+client_select+&#39;.csv&#39;) print(&#39;These are the locations in this file: &#39;) client_df.county . Select Client: pepsi These are the locations in this file: . 0 Bexar 1 Boone 2 Broome 3 Campbell 4 Clark 5 Clinton 6 Cook 7 Craighead 8 Dallas 9 DENVER 10 Fort Bend 11 Giles 12 Harford 13 Houston 14 Kern 15 Lincoln 16 Linn 17 Lycoming 18 Mecklenburg 19 Norfolk 20 Orange 21 Pinal 22 Rock 23 Salt Lake 24 San Bernardino 25 Shawnee 26 Stanislaus 27 Stark 28 Tarrant 29 Vermilion 30 Wayne 31 Windham 32 York Name: county, dtype: object . PULL THE LINLAB DATA . linlab=pd.read_csv(&#39;../data/sources/linlab/rtcountylevel.csv&#39;) cols=[&#39;uid&#39;, &#39;dispID&#39;, &#39;date&#39;,&#39;date_lag&#39;, &#39;Rt_plot&#39;, &#39;Rt_upr&#39;, &#39;Rt_lwr&#39;, &#39;Rt_loess_fit&#39;, &#39;Rt_loess_lwr&#39;, &#39;Rt_loess_upr&#39;, &#39;positiveIncrease&#39;, &#39;positive&#39;, &#39;positive_7day&#39;, &#39;positive_percapita&#39;, &#39;positiveIncr_percapita&#39;, &#39;deathIncrease&#39;, &#39;death&#39;, &#39;death_percapita&#39;, &#39;deathIncr_percapita&#39;] linlab_df=linlab[cols] . MERGE CLIENT AND LINLAB AND DISPLAY DATES . Client_Linlab=pd.merge(client_df, linlab_df, how=&#39;left&#39;) Client_Linlab.sort_values([&#39;state&#39;,&#39;date&#39;], ascending=False, inplace=True) Client_Linlab.date . MergeError Traceback (most recent call last) &lt;ipython-input-24-b27fe00cb71e&gt; in &lt;module&gt; -&gt; 1 Client_Linlab=pd.merge(client_df, linlab_df, how=&#39;left&#39;) 2 Client_Linlab.sort_values([&#39;state&#39;,&#39;date&#39;], ascending=False, inplace=True) 3 Client_Linlab.date C: Users anaconda3 envs USAcovidMAP lib site-packages pandas core reshape merge.py in merge(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate) 71 validate=None, 72 ) -&gt; &#34;DataFrame&#34;: &gt; 73 op = _MergeOperation( 74 left, 75 right, C: Users anaconda3 envs USAcovidMAP lib site-packages pandas core reshape merge.py in __init__(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate) 618 warnings.warn(msg, UserWarning) 619 --&gt; 620 self._validate_specification() 621 622 # note this function has side effects C: Users anaconda3 envs USAcovidMAP lib site-packages pandas core reshape merge.py in _validate_specification(self) 1189 common_cols = self.left.columns.intersection(self.right.columns) 1190 if len(common_cols) == 0: -&gt; 1191 raise MergeError( 1192 &#34;No common columns to perform merge on. &#34; 1193 &#34;Merge options: left_on={lon}, right_on={ron}, &#34; MergeError: No common columns to perform merge on. Merge options: left_on=None, right_on=None, left_index=False, right_index=False . #SELECT THE DATE TO PULL select_date=input(&#39;Select Date: &#39;) print_date=input(&#39;Select Date: &#39;) Client_Linlab=Client_Linlab[Client_Linlab[&#39;date&#39;]==select_date] Client_Linlab.sort_values([&#39;state&#39;, &#39;county&#39;], inplace=True) . #VIEW DATASET TO VERIFY BEFORE DOWNLOAD Client_Linlab . DOWNLOAD THE FILE . Client_Linlab.to_csv(&#39;../data/clients/&#39;+client_select+&#39;/&#39;+date+&#39;-LinLab.csv&#39;) Client_Linlab.to_csv(&#39;../data/clients/&#39;+client_select+&#39;/&#39;+print_date+&#39;-LinLab.csv&#39;) .",
            "url": "https://richcastro82.github.io/Notebooks/2020/09/02/Client_LinLab.html",
            "relUrl": "/2020/09/02/Client_LinLab.html",
            "date": " • Sep 2, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "US COUNTY LEVEL MAP",
            "content": "THIS IS A TEST OF THE MATPLOTLIB MAPPING SYSTEM. . #collapse-hide client=input(&#39;Client Name: &#39;) client=client.lower() client . . Client Name: kelloggs . &#39;kelloggs&#39; . #plot deaths . #plot cases . #plot testing . #collapse-hide #IMPORT LIBRARIES import pandas as pd import numpy as np from matplotlib import pyplot as plt from mpl_toolkits.basemap import Basemap cities = pd.read_csv(&#39;../_data/client_locations/&#39; + client + &#39;Cleaned.csv&#39;) lat = cities[&#39;lat_&#39;].values lon = cities[&#39;long&#39;].values population = cities[&#39;active&#39;].values area = cities[&#39;tee&#39;].values . . #collapse-hide fig = plt.figure(figsize=(18, 10)) m = Basemap(llcrnrlon=-119,llcrnrlat=22,urcrnrlon=-64,urcrnrlat=49, projection=&#39;lcc&#39;, resolution=&#39;l&#39;, lat_1=33,lat_2=45,lon_0=-95) m.shadedrelief() m.drawcoastlines(color=&#39;gray&#39;) m.drawcountries(color=&#39;gray&#39;) m.drawstates(color=&#39;gray&#39;) m.drawcounties(color=&#39;gray&#39;) m.scatter(lon, lat, latlon=True, c=np.log10(population), s=area, cmap=&#39;Reds&#39;, alpha=1) client=client.upper() plt.title(client + &quot; Locations&quot;) plt.colorbar(label=r&#39;Covid Cases(Active)&#39;) plt.clim(3, 7) . . #collapse-hide import warnings warnings.filterwarnings(&#39;ignore&#39;) rt=pd.read_csv(&#39;../_data/_misc/rt.csv&#39;) rta=rt[rt[&#39;region&#39;]==&#39;AR&#39;] rta[&#39;date&#39;] = pd.to_datetime(rta[&#39;date&#39;]) rta.set_index(&#39;date&#39;, inplace=True) rta=rta.sort_values(&#39;date&#39;, ascending=False) rt2=pd.read_csv(&#39;../_data/_misc/rt.csv&#39;) rta2=rt[rt2[&#39;region&#39;]==&#39;NY&#39;] rta2[&#39;date&#39;] = pd.to_datetime(rta2[&#39;date&#39;]) rta2.set_index(&#39;date&#39;, inplace=True) rta2=rta2.sort_values(&#39;date&#39;, ascending=False) rt3=pd.read_csv(&#39;../_data/_misc/rt.csv&#39;) rta3=rt[rt3[&#39;region&#39;]==&#39;NJ&#39;] rta3[&#39;date&#39;] = pd.to_datetime(rta3[&#39;date&#39;]) rta3.set_index(&#39;date&#39;, inplace=True) rta3=rta3.sort_values(&#39;date&#39;, ascending=False) rt4=pd.read_csv(&#39;../_data/_misc/rt.csv&#39;) rta4=rt[rt4[&#39;region&#39;]==&#39;WA&#39;] rta4[&#39;date&#39;] = pd.to_datetime(rta4[&#39;date&#39;]) rta4.set_index(&#39;date&#39;, inplace=True) rta4=rta4.sort_values(&#39;date&#39;, ascending=False) rt5=pd.read_csv(&#39;../_data/_misc/rt.csv&#39;) rta5=rt[rt5[&#39;region&#39;]==&#39;TN&#39;] rta5[&#39;date&#39;] = pd.to_datetime(rta5[&#39;date&#39;]) rta5.set_index(&#39;date&#39;, inplace=True) rta5=rta5.sort_values(&#39;date&#39;, ascending=False) . . #collapse-hide rta2[&#39;mean&#39;].plot() rta5[&#39;mean&#39;].plot() rta3[&#39;mean&#39;].plot() . . &lt;matplotlib.axes._subplots.AxesSubplot at 0x2290036c5e0&gt; .",
            "url": "https://richcastro82.github.io/Notebooks/matrix/2020/09/02/Client-Location-Map-Code.html",
            "relUrl": "/matrix/2020/09/02/Client-Location-Map-Code.html",
            "date": " • Sep 2, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "BUILD OUT CLIENT LOCATION FILES",
            "content": "THIS MODULE WILL TAKE A EXCEL FILE WITH JUST THE COUNTY AND STATE OF ANY CLIENT LOCATIONS AND BUILD OUT AN EXCEL FILE THAT INCLUDES THE FIPS CODE, POPULATION, LAT/LONG POSITIONS FOR MAP BUILDING, AND INDEXES THE TABLE ON THE FIP COLUMN . #collapse-hide client=input(&#39;Client Name : &#39;) print(&#39;PULLING STATE AND COUNTY LOCATIONS FOR: &#39; + client.upper()) clientLocations=pd.read_csv(&#39;../data/clients/&#39;+client+&#39;/&#39;+client+&#39;.csv&#39;) clientLocations.columns = map(str.lower, clientLocations.columns) clientLocations . . Client Name : kelloggs PULLING STATE AND COUNTY LOCATIONS FOR: KELLOGGS . state county . 0 Colorado | Arapahoe | . 1 Arkansas | Benton | . 2 Michigan | Calhoun | . 3 New Jersey | Camden | . 4 Illinois | Cook | . 5 Tennessee | Davidson | . 6 Nebraska | Douglas | . 7 Illinois | DuPage | . 8 Tennessee | Fayette | . 9 Georgia | Floyd | . 10 Ohio | Hamilton | . 11 Minnesota | Hennepin | . 12 Florida | Hillsborough | . 13 Michigan | Kent | . 14 Pennsylvania | Lancaster | . 15 Pennsylvania | Lycoming | . 16 Tennessee | Madison | . 17 Pennsylvania | Montgomery | . 18 Ohio | Muskingum | . 19 Kentucky | Pike | . 20 California | San Diego | . 21 California | Santa Clara | . 22 Tennessee | Shelby | . 23 North Carolina | Wake | . 24 Kansas | Wyandotte | . clientLocations.columns . Index([&#39;state&#39;, &#39;county&#39;], dtype=&#39;object&#39;) . #collapse-hide cenLat=pd.read_csv(&#39;../data/sources/Census/Geo-Fips.csv&#39;) cenLat . . fips county state country lat long combined_key . 0 45001 | Abbeville | South Carolina | US | 34.223334 | -82.461707 | Abbeville, South Carolina, US | . 1 22001 | Acadia | Louisiana | US | 30.295065 | -92.414197 | Acadia, Louisiana, US | . 2 51001 | Accomack | Virginia | US | 37.767072 | -75.632346 | Accomack, Virginia, US | . 3 16001 | Ada | Idaho | US | 43.452658 | -116.241552 | Ada, Idaho, US | . 4 19001 | Adair | Iowa | US | 41.330756 | -94.471059 | Adair, Iowa, US | . ... ... | ... | ... | ... | ... | ... | ... | . 3239 78 | NaN | Virgin Islands | US | 18.335800 | -64.896300 | Virgin Islands, US | . 3240 90048 | Unassigned | Texas | US | NaN | NaN | Unassigned, Texas, US | . 3241 90023 | Unassigned | Maine | US | NaN | NaN | Unassigned, Maine, US | . 3242 16061 | Lewis | Idaho | US | 46.233153 | -116.434146 | Lewis, Idaho, US | . 3243 41069 | Wheeler | Oregon | US | 44.726982 | -120.028143 | Wheeler, Oregon, US | . 3244 rows × 7 columns . #collapse-hide clm=pd.merge(cenLat, clientLocations, on=[&#39;state&#39;, &#39;county&#39;]) clmCol=[ &#39;fips&#39;, &#39;country&#39;, &#39;state&#39;, &#39;county&#39;, &#39;lat&#39;, &#39;long&#39;] clientDataCleaned=clm[clmCol] . . &lt;ipython-input-104-4478517d623a&gt;:5: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy clientDataCleaned[&#39;fips&#39;]+=84000000 . 0 84008005 1 84005007 2 84026025 3 84034007 4 84017031 5 84047037 6 84031055 7 84017043 8 84047047 9 84013115 10 84039061 11 84027053 12 84012057 13 84026081 14 84042071 15 84042081 16 84047113 17 84042091 18 84039119 19 84021195 20 84006073 21 84006085 22 84047157 23 84037183 24 84020209 Name: fips, dtype: int64 . #collapse-hide cen=pd.read_csv(&#39;../data/sources/Census/Census_2019.csv&#39;) cCol=[&#39;state&#39;, &#39;county&#39;, &#39;pop19&#39;] censusData=cen[cCol] censusData . . state county pop19 . 0 Alabama | Autauga | 55869 | . 1 Alabama | Baldwin | 223234 | . 2 Alabama | Barbour | 24686 | . 3 Alabama | Bibb | 22394 | . 4 Alabama | Blount | 57826 | . ... ... | ... | ... | . 3137 Wyoming | Sweetwater | 42343 | . 3138 Wyoming | Teton | 23464 | . 3139 Wyoming | Uinta | 20226 | . 3140 Wyoming | Washakie | 7805 | . 3141 Wyoming | Weston | 6927 | . 3142 rows × 3 columns . #collapse-hide ClientCensusCleaned=pd.merge(clientDataCleaned, censusData, on=[&#39;state&#39;,&#39;county&#39;], how=&#39;left&#39;) ClientCensusCleaned.set_index(&#39;fips&#39;, inplace=True) clientDataCleaned.shape . . (25, 6) . #collapse-hide print(&#39;THIS IS THE ORIGINAL LOCATIONS FILE FOR:&#39; + client) clientLocations . . THIS IS THE ORIGINAL LOCATIONS FILE FOR:kelloggs . state county . 0 Colorado | Arapahoe | . 1 Arkansas | Benton | . 2 Michigan | Calhoun | . 3 New Jersey | Camden | . 4 Illinois | Cook | . 5 Tennessee | Davidson | . 6 Nebraska | Douglas | . 7 Illinois | DuPage | . 8 Tennessee | Fayette | . 9 Georgia | Floyd | . 10 Ohio | Hamilton | . 11 Minnesota | Hennepin | . 12 Florida | Hillsborough | . 13 Michigan | Kent | . 14 Pennsylvania | Lancaster | . 15 Pennsylvania | Lycoming | . 16 Tennessee | Madison | . 17 Pennsylvania | Montgomery | . 18 Ohio | Muskingum | . 19 Kentucky | Pike | . 20 California | San Diego | . 21 California | Santa Clara | . 22 Tennessee | Shelby | . 23 North Carolina | Wake | . 24 Kansas | Wyandotte | . #collapse-hide print(&#39;THIS IS THE LAT/LONG AND FIPS CODES DATASET&#39;) cenLat.head(3) . . THIS IS THE LAT/LONG AND FIPS CODES DATASET . fips county state country lat long combined_key . 0 45001 | Abbeville | South Carolina | US | 34.223334 | -82.461707 | Abbeville, South Carolina, US | . 1 22001 | Acadia | Louisiana | US | 30.295065 | -92.414197 | Acadia, Louisiana, US | . 2 51001 | Accomack | Virginia | US | 37.767072 | -75.632346 | Accomack, Virginia, US | . #collapse-hide print(&#39;THIS IS THE CENSUS POPULATION DATASET&#39;) censusData.head(3) . . THIS IS THE CENSUS POPULATION DATASET . state county pop19 . 0 Alabama | Autauga | 55869 | . 1 Alabama | Baldwin | 223234 | . 2 Alabama | Barbour | 24686 | . #collapse-hide print(&#39;THIS IS THE NEW CLIENT LOCATIONS FILE&#39;) ClientCensusCleaned . . THIS IS THE NEW CLIENT LOCATIONS FILE . country state county lat long pop19 . fips . 8005 US | Colorado | Arapahoe | 39.649775 | -104.335362 | 656590 | . 5007 US | Arkansas | Benton | 36.336447 | -94.256808 | 279141 | . 26025 US | Michigan | Calhoun | 42.246338 | -85.004936 | 134159 | . 34007 US | New Jersey | Camden | 39.803438 | -74.963888 | 506471 | . 17031 US | Illinois | Cook | 41.841448 | -87.816588 | 5150233 | . 47037 US | Tennessee | Davidson | 36.170074 | -86.786461 | 694144 | . 31055 US | Nebraska | Douglas | 41.295183 | -96.150853 | 571327 | . 17043 US | Illinois | DuPage | 41.851170 | -88.086427 | 922921 | . 47047 US | Tennessee | Fayette | 35.196158 | -89.413990 | 41133 | . 13115 US | Georgia | Floyd | 34.262683 | -85.215774 | 98498 | . 39061 US | Ohio | Hamilton | 39.196736 | -84.545029 | 817473 | . 27053 US | Minnesota | Hennepin | 45.007615 | -93.476949 | 1265843 | . 12057 US | Florida | Hillsborough | 27.927656 | -82.320132 | 1471968 | . 26081 US | Michigan | Kent | 43.031977 | -85.549346 | 656955 | . 42071 US | Pennsylvania | Lancaster | 40.039046 | -76.247701 | 545724 | . 42081 US | Pennsylvania | Lycoming | 41.343105 | -77.066300 | 113299 | . 47113 US | Tennessee | Madison | 35.611820 | -88.840760 | 97984 | . 42091 US | Pennsylvania | Montgomery | 40.210537 | -75.366523 | 830915 | . 39119 US | Ohio | Muskingum | 39.965760 | -81.943633 | 86215 | . 21195 US | Kentucky | Pike | 37.470883 | -82.394874 | 57876 | . 6073 US | California | San Diego | 33.034846 | -116.736533 | 3338330 | . 6085 US | California | Santa Clara | 37.231049 | -121.697046 | 1927852 | . 47157 US | Tennessee | Shelby | 35.186478 | -89.896924 | 937166 | . 37183 US | North Carolina | Wake | 35.788793 | -78.652492 | 1111761 | . 20209 US | Kansas | Wyandotte | 39.117273 | -94.763782 | 165429 | . #collapse-hide ClientCensusCleaned.to_csv(&#39;../data/clients/&#39; +client+&#39;/&#39;+client+&#39;-Cleaned.csv&#39;) print(&#39;MERGED THE ORIGINAL &#39; + client + &#39; LOCATIONS FILE AND ADDED CENSUS DATA, FIPS CODES, AND LAT/LONG&#39;) print (&#39;NEW FILE CAN BE FOUND AT: DATA/SOURCES/CLIENTS/&#39;+client+&#39;/&#39; + client + &#39;-Cleaned.csv&#39;) . . MERGED THE ORIGINAL kelloggs LOCATIONS FILE AND ADDED CENSUS DATA, FIPS CODES, AND LAT/LONG NEW FILE CAN BE FOUND AT: DATA/SOURCES/CLIENTS/kelloggs/kelloggs-Cleaned.csv .",
            "url": "https://richcastro82.github.io/Notebooks/matrix/2020/09/02/Build-Client-Location-Files.html",
            "relUrl": "/matrix/2020/09/02/Build-Client-Location-Files.html",
            "date": " • Sep 2, 2020"
        }
        
    
  
    
        ,"post8": {
            "title": "A&W CANADA DATASET",
            "content": "#IMPORTING EXTERNAL LIBRARIES AND SETTING THE DATE AND WEEK RANGE. import pandas as pd import datetime import numpy as np from pivottablejs import pivot_ui date=datetime.datetime.now().strftime(&quot;%Y-%m-%d&quot;) print (date) #SET 7 DAYS TIMEFRAME FROM TODAYS DATE weekly=pd.date_range(end=date, periods=7).strftime(&quot;%Y-%m-%d&quot;) biweekly=pd.date_range(end=date, periods=14) print(weekly) print (biweekly) df_cl.columns . 2020-08-30 Index([&#39;2020-08-24&#39;, &#39;2020-08-25&#39;, &#39;2020-08-26&#39;, &#39;2020-08-27&#39;, &#39;2020-08-28&#39;, &#39;2020-08-29&#39;, &#39;2020-08-30&#39;], dtype=&#39;object&#39;) DatetimeIndex([&#39;2020-08-17&#39;, &#39;2020-08-18&#39;, &#39;2020-08-19&#39;, &#39;2020-08-20&#39;, &#39;2020-08-21&#39;, &#39;2020-08-22&#39;, &#39;2020-08-23&#39;, &#39;2020-08-24&#39;, &#39;2020-08-25&#39;, &#39;2020-08-26&#39;, &#39;2020-08-27&#39;, &#39;2020-08-28&#39;, &#39;2020-08-29&#39;, &#39;2020-08-30&#39;], dtype=&#39;datetime64[ns]&#39;, freq=&#39;D&#39;) . Index([&#39;region&#39;, &#39;reg_pop&#39;, &#39;prov_pop&#39;], dtype=&#39;object&#39;) . #IMPORTING DATASETS from datetime import datetime df_ca= pd.read_csv(&#39;../_data/Data_Sources/Canada/hrcases.csv&#39;) df_cl=pd.read_csv(&#39;../_data/client_locations/anw_canada.csv&#39;) #canada_Population=pd.read_csv(&#39;../_data/data_resources/canada/caCensus.csv&#39;) df_cl=df_cl.set_index(&#39;province&#39;) df_ca.rename(columns={&#39;health_region&#39;:&#39;region&#39;, &#39;date_report&#39;:&#39;date&#39;}, inplace=True) df_ca[&#39;date&#39;] = df_ca[&#39;date&#39;].astype(&#39;datetime64&#39;) df_ca.set_index(&#39;date&#39;, inplace=True) df_ca . KeyError Traceback (most recent call last) &lt;ipython-input-89-4ad7350e31fe&gt; in &lt;module&gt; 9 df_ca[&#39;date&#39;] = df_ca[&#39;date&#39;].astype(&#39;datetime64&#39;) 10 df_ca.set_index(&#39;date&#39;, inplace=True) &gt; 11 df_ca[[&#39;date&#39;]]==&#39;2020-01-25&#39; C: Users anaconda3 envs USAcovidMAP lib site-packages pandas core frame.py in __getitem__(self, key) 2804 if is_iterator(key): 2805 key = list(key) -&gt; 2806 indexer = self.loc._get_listlike_indexer(key, axis=1, raise_missing=True)[1] 2807 2808 # take() does not accept boolean indexers C: Users anaconda3 envs USAcovidMAP lib site-packages pandas core indexing.py in _get_listlike_indexer(self, key, axis, raise_missing) 1550 keyarr, indexer, new_indexer = ax._reindex_non_unique(keyarr) 1551 -&gt; 1552 self._validate_read_indexer( 1553 keyarr, indexer, o._get_axis_number(axis), raise_missing=raise_missing 1554 ) C: Users anaconda3 envs USAcovidMAP lib site-packages pandas core indexing.py in _validate_read_indexer(self, key, indexer, axis, raise_missing) 1638 if missing == len(indexer): 1639 axis_name = self.obj._get_axis_name(axis) -&gt; 1640 raise KeyError(f&#34;None of [{key}] are in the [{axis_name}]&#34;) 1641 1642 # We (temporarily) allow for some missing keys with .loc, except in KeyError: &#34;None of [Index([&#39;date&#39;], dtype=&#39;object&#39;)] are in the [columns]&#34; . #MERGING DATASETS print (df_ca.columns) print(df_cl.columns) print (df_cl.shape) print(df_ca.shape) #client locations and add population data to them. #merge clientCleaned with canada data #sort the dataset by the culmulative and then the county #print the dataset and save it the client/dataset folder with a datestamp . #EXPORTING WEEKLY REPORT #FIGURE OUT HOW TO SOMEHOW MATCH THE DATING TO THE WEIRDNESS IN THE FILE. #SAVE THE FILE TO THE DATA FOLDER WITH A DATE STAMP . #EXPORTING DAILY REPORT #SAVE THE DAILY REPORT TO DATA FOLDER WITH A DATE STAMP . REPLACED SOME COUNTIES TO FILL DATA . #REPLACED SOME LOCATIONS BUT THERE IS A COLUMN TO INDICATE IT. .",
            "url": "https://richcastro82.github.io/Notebooks/matrix/2020/09/02/A&W-CANADA-DATASET-BUILDER.html",
            "relUrl": "/matrix/2020/09/02/A&W-CANADA-DATASET-BUILDER.html",
            "date": " • Sep 2, 2020"
        }
        
    
  
    
        ,"post9": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://richcastro82.github.io/Notebooks/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This is where you put the contents of your About page. Like all your pages, it’s in Markdown format. . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://richcastro82.github.io/Notebooks/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://richcastro82.github.io/Notebooks/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}